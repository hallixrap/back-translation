[
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 75.52486292691987,
    "chrf": 87.35416380339747,
    "bertscore_precision": 0.9592853784561157,
    "bertscore_recall": 0.9675506353378296,
    "bertscore_f1": 0.9634002447128296,
    "labse_similarity": 0.9344627857208252,
    "comet_score": 0.9104897975921631,
    "flesch_reading_ease": 74.512711927982,
    "flesch_kincaid_grade": 6.312235558889725,
    "composite_score": 0.9100911885880707,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 77.99351161394581,
    "chrf": 88.3503682624764,
    "bertscore_precision": 0.9865767955780029,
    "bertscore_recall": 0.9870954751968384,
    "bertscore_f1": 0.9868360757827759,
    "labse_similarity": 0.9335215091705322,
    "comet_score": 0.9130752086639404,
    "flesch_reading_ease": 73.36677871570699,
    "flesch_kincaid_grade": 6.45604260878304,
    "composite_score": 0.9215429907425847,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 71.9425294838212,
    "chrf": 87.17590588795446,
    "bertscore_precision": 0.9566502571105957,
    "bertscore_recall": 0.968668520450592,
    "bertscore_f1": 0.9626219272613525,
    "labse_similarity": 0.9225522875785828,
    "comet_score": 0.9048775434494019,
    "flesch_reading_ease": 73.75094816986666,
    "flesch_kincaid_grade": 6.3224858917368145,
    "composite_score": 0.9022228098722257,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 42.73606710785876,
    "chrf": 71.84132790674975,
    "bertscore_precision": 0.9502811431884766,
    "bertscore_recall": 0.9551476240158081,
    "bertscore_f1": 0.9527081251144409,
    "labse_similarity": 0.9174709320068359,
    "comet_score": 0.8909912109375,
    "flesch_reading_ease": 69.01653719385843,
    "flesch_kincaid_grade": 7.153636986636645,
    "composite_score": 0.8425524856380577,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 47.76024478274306,
    "chrf": 74.0139121333619,
    "bertscore_precision": 0.9533066749572754,
    "bertscore_recall": 0.9576045274734497,
    "bertscore_f1": 0.9554507732391357,
    "labse_similarity": 0.9068507552146912,
    "comet_score": 0.898280143737793,
    "flesch_reading_ease": 66.21864420313003,
    "flesch_kincaid_grade": 7.260732460342808,
    "composite_score": 0.8513565319319131,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 41.2637291775002,
    "chrf": 70.12449462054849,
    "bertscore_precision": 0.93012934923172,
    "bertscore_recall": 0.9467964172363281,
    "bertscore_f1": 0.9383888840675354,
    "labse_similarity": 0.8864527940750122,
    "comet_score": 0.8877975940704346,
    "flesch_reading_ease": 65.50568735035034,
    "flesch_kincaid_grade": 7.373531953243035,
    "composite_score": 0.8272070936611946,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 55.171346388303085,
    "chrf": 76.19716425081113,
    "bertscore_precision": 0.9491186141967773,
    "bertscore_recall": 0.9569849967956543,
    "bertscore_f1": 0.9530355930328369,
    "labse_similarity": 0.9088096022605896,
    "comet_score": 0.8962745070457458,
    "flesch_reading_ease": 72.95237450031559,
    "flesch_kincaid_grade": 6.221298548285294,
    "composite_score": 0.8612083178879252,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 62.79958380597945,
    "chrf": 79.89586360529852,
    "bertscore_precision": 0.9739714860916138,
    "bertscore_recall": 0.9738957285881042,
    "bertscore_f1": 0.9739336371421814,
    "labse_similarity": 0.9034906029701233,
    "comet_score": 0.902977466583252,
    "flesch_reading_ease": 72.31315963606289,
    "flesch_kincaid_grade": 6.472109181141441,
    "composite_score": 0.8812659575964193,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 55.63188685753932,
    "chrf": 75.50753977068074,
    "bertscore_precision": 0.9489139914512634,
    "bertscore_recall": 0.9623695015907288,
    "bertscore_f1": 0.9555943608283997,
    "labse_similarity": 0.8740135431289673,
    "comet_score": 0.8932713270187378,
    "flesch_reading_ease": 73.41136999140828,
    "flesch_kincaid_grade": 6.329615975422428,
    "composite_score": 0.8536920451425581,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 64.79276625049091,
    "chrf": 82.16595341359321,
    "bertscore_precision": 0.9434120655059814,
    "bertscore_recall": 0.9506486058235168,
    "bertscore_f1": 0.9470165371894836,
    "labse_similarity": 0.8882166743278503,
    "comet_score": 0.9044369459152222,
    "flesch_reading_ease": 73.33085896860615,
    "flesch_kincaid_grade": 6.487765368699208,
    "composite_score": 0.8758992288721015,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 75.70470008586966,
    "chrf": 87.6502892458657,
    "bertscore_precision": 0.9784250259399414,
    "bertscore_recall": 0.9786508083343506,
    "bertscore_f1": 0.978537917137146,
    "labse_similarity": 0.9076958894729614,
    "comet_score": 0.907008707523346,
    "flesch_reading_ease": 74.57624423963136,
    "flesch_kincaid_grade": 6.223236047107015,
    "composite_score": 0.9090328638712408,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 72.20809830227178,
    "chrf": 85.53956616404005,
    "bertscore_precision": 0.9681509733200073,
    "bertscore_recall": 0.971394956111908,
    "bertscore_f1": 0.9697703123092651,
    "labse_similarity": 0.8687182068824768,
    "comet_score": 0.894263505935669,
    "flesch_reading_ease": 73.34503985696193,
    "flesch_kincaid_grade": 6.49914375822593,
    "composite_score": 0.8887580591015241,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 51.2970332456777,
    "chrf": 74.50361782525621,
    "bertscore_precision": 0.9646666646003723,
    "bertscore_recall": 0.9685813188552856,
    "bertscore_f1": 0.9666200280189514,
    "labse_similarity": 0.8662760853767395,
    "comet_score": 0.8943027257919312,
    "flesch_reading_ease": 70.12109485873495,
    "flesch_kincaid_grade": 6.777858168995692,
    "composite_score": 0.849869366912578,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 49.01732828612875,
    "chrf": 72.50385138252489,
    "bertscore_precision": 0.9639688730239868,
    "bertscore_recall": 0.9658598303794861,
    "bertscore_f1": 0.9649134874343872,
    "labse_similarity": 0.8642598390579224,
    "comet_score": 0.8995206356048584,
    "flesch_reading_ease": 68.74949657869014,
    "flesch_kincaid_grade": 6.843618985554471,
    "composite_score": 0.8449792783030314,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 48.96304216334848,
    "chrf": 73.19612584186247,
    "bertscore_precision": 0.9456674456596375,
    "bertscore_recall": 0.9574296474456787,
    "bertscore_f1": 0.9515121579170227,
    "labse_similarity": 0.8485052585601807,
    "comet_score": 0.8971240520477295,
    "flesch_reading_ease": 72.29652254192955,
    "flesch_kincaid_grade": 6.435710109247577,
    "composite_score": 0.8381929430252174,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 65.43601296305337,
    "chrf": 82.918741779494,
    "bertscore_precision": 0.9510796070098877,
    "bertscore_recall": 0.9570947289466858,
    "bertscore_f1": 0.9540777206420898,
    "labse_similarity": 0.9381988048553467,
    "comet_score": 0.9060851335525513,
    "flesch_reading_ease": 72.57071657839835,
    "flesch_kincaid_grade": 6.7166682715454975,
    "composite_score": 0.8901984861841284,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 61.93018565690467,
    "chrf": 80.5499184921106,
    "bertscore_precision": 0.9681982398033142,
    "bertscore_recall": 0.970741331577301,
    "bertscore_f1": 0.9694681167602539,
    "labse_similarity": 0.9102874398231506,
    "comet_score": 0.903134822845459,
    "flesch_reading_ease": 69.31116449736916,
    "flesch_kincaid_grade": 6.98339241207422,
    "composite_score": 0.8814366920991417,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 63.645559086584726,
    "chrf": 82.85363214509371,
    "bertscore_precision": 0.9447458982467651,
    "bertscore_recall": 0.9584709405899048,
    "bertscore_f1": 0.9515589475631714,
    "labse_similarity": 0.9092470407485962,
    "comet_score": 0.9009430408477783,
    "flesch_reading_ease": 74.41888879173987,
    "flesch_kincaid_grade": 6.201149361333453,
    "composite_score": 0.8804788599348405,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 47.43048573505099,
    "chrf": 75.56057918458129,
    "bertscore_precision": 0.940601110458374,
    "bertscore_recall": 0.9466663599014282,
    "bertscore_f1": 0.9436240196228027,
    "labse_similarity": 0.8995851278305054,
    "comet_score": 0.8989095091819763,
    "flesch_reading_ease": 69.39178169734153,
    "flesch_kincaid_grade": 6.955046012269939,
    "composite_score": 0.8485029632603589,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 45.1116369865915,
    "chrf": 72.2058055802342,
    "bertscore_precision": 0.9549075365066528,
    "bertscore_recall": 0.9588587880134583,
    "bertscore_f1": 0.9568790197372437,
    "labse_similarity": 0.886597752571106,
    "comet_score": 0.8954150676727295,
    "flesch_reading_ease": 66.6538293741854,
    "flesch_kincaid_grade": 7.02551952343363,
    "composite_score": 0.8416573687105195,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 37.76505754738755,
    "chrf": 66.94290567579894,
    "bertscore_precision": 0.9362126588821411,
    "bertscore_recall": 0.9513728618621826,
    "bertscore_f1": 0.9437318444252014,
    "labse_similarity": 0.8672877550125122,
    "comet_score": 0.8791862726211548,
    "flesch_reading_ease": 67.68397541830204,
    "flesch_kincaid_grade": 7.0853342973214914,
    "composite_score": 0.8145530885464375,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 66.08534775422996,
    "chrf": 84.18803502925957,
    "bertscore_precision": 0.9564571976661682,
    "bertscore_recall": 0.9568684101104736,
    "bertscore_f1": 0.9566627740859985,
    "labse_similarity": 0.9300005435943604,
    "comet_score": 0.8895843625068665,
    "flesch_reading_ease": 75.93682325464749,
    "flesch_kincaid_grade": 6.332644597009313,
    "composite_score": 0.8877624318695074,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 72.37315069288321,
    "chrf": 84.62126748738244,
    "bertscore_precision": 0.9837803244590759,
    "bertscore_recall": 0.9830987453460693,
    "bertscore_f1": 0.9834393858909607,
    "labse_similarity": 0.9222379922866821,
    "comet_score": 0.9091413021087646,
    "flesch_reading_ease": 73.86036656891497,
    "flesch_kincaid_grade": 6.483362658846531,
    "composite_score": 0.9060697916757726,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 60.84574418361694,
    "chrf": 81.92234430930844,
    "bertscore_precision": 0.9402227401733398,
    "bertscore_recall": 0.9527716040611267,
    "bertscore_f1": 0.9464555382728577,
    "labse_similarity": 0.8930004239082336,
    "comet_score": 0.887768566608429,
    "flesch_reading_ease": 76.96184362315745,
    "flesch_kincaid_grade": 6.154948372854804,
    "composite_score": 0.8682081485631907,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 74.3212454329491,
    "chrf": 89.22080710299593,
    "bertscore_precision": 0.9631490707397461,
    "bertscore_recall": 0.9673990607261658,
    "bertscore_f1": 0.9652693867683411,
    "labse_similarity": 0.9380174279212952,
    "comet_score": 0.9163106679916382,
    "flesch_reading_ease": 66.9452596259626,
    "flesch_kincaid_grade": 8.382468646864687,
    "composite_score": 0.9144144247001138,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 84.32742846093024,
    "chrf": 92.8948827526565,
    "bertscore_precision": 0.9919501543045044,
    "bertscore_recall": 0.9917779564857483,
    "bertscore_f1": 0.9918639659881592,
    "labse_similarity": 0.9377753734588623,
    "comet_score": 0.9213733673095703,
    "flesch_reading_ease": 66.21767816091956,
    "flesch_kincaid_grade": 8.34593614303959,
    "composite_score": 0.9391273589055278,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 61.808191802559534,
    "chrf": 84.36944921857058,
    "bertscore_precision": 0.9457008838653564,
    "bertscore_recall": 0.953506588935852,
    "bertscore_f1": 0.9495877027511597,
    "labse_similarity": 0.9275935888290405,
    "comet_score": 0.9097970724105835,
    "flesch_reading_ease": 65.43892307692312,
    "flesch_kincaid_grade": 8.653299145299144,
    "composite_score": 0.8862066623242171,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 51.14664195493774,
    "chrf": 77.8517642659444,
    "bertscore_precision": 0.9368242025375366,
    "bertscore_recall": 0.9429273009300232,
    "bertscore_f1": 0.9398658871650696,
    "labse_similarity": 0.8768011927604675,
    "comet_score": 0.905689001083374,
    "flesch_reading_ease": 61.02581190380225,
    "flesch_kincaid_grade": 9.31300443369609,
    "composite_score": 0.8516665433263122,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 60.729726217758795,
    "chrf": 80.43313884130411,
    "bertscore_precision": 0.9678093194961548,
    "bertscore_recall": 0.9672661423683167,
    "bertscore_f1": 0.9675376415252686,
    "labse_similarity": 0.8650338053703308,
    "comet_score": 0.9190974235534668,
    "flesch_reading_ease": 63.93750211709741,
    "flesch_kincaid_grade": 8.542521243977223,
    "composite_score": 0.8744218438997284,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 42.01247780054239,
    "chrf": 72.83336830462179,
    "bertscore_precision": 0.9242677688598633,
    "bertscore_recall": 0.9356787800788879,
    "bertscore_f1": 0.9299383163452148,
    "labse_similarity": 0.8594977259635925,
    "comet_score": 0.9002463221549988,
    "flesch_reading_ease": 55.86280555555555,
    "flesch_kincaid_grade": 9.884083333333336,
    "composite_score": 0.8272051508925078,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 62.98429443410484,
    "chrf": 82.2204458410838,
    "bertscore_precision": 0.9538984298706055,
    "bertscore_recall": 0.9583221673965454,
    "bertscore_f1": 0.9561051726341248,
    "labse_similarity": 0.887295663356781,
    "comet_score": 0.9111433029174805,
    "flesch_reading_ease": 66.18547819971872,
    "flesch_kincaid_grade": 8.38907172995781,
    "composite_score": 0.8783914733866941,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 60.3395395658946,
    "chrf": 79.38586165649899,
    "bertscore_precision": 0.9680992364883423,
    "bertscore_recall": 0.9674091935157776,
    "bertscore_f1": 0.967754065990448,
    "labse_similarity": 0.8966547846794128,
    "comet_score": 0.9146980047225952,
    "flesch_reading_ease": 64.08135888294714,
    "flesch_kincaid_grade": 8.450688057040999,
    "composite_score": 0.8777500099643087,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 43.55590246735925,
    "chrf": 72.71340301265616,
    "bertscore_precision": 0.9283738136291504,
    "bertscore_recall": 0.940317690372467,
    "bertscore_f1": 0.9343076348304749,
    "labse_similarity": 0.891066312789917,
    "comet_score": 0.8995708227157593,
    "flesch_reading_ease": 62.391454545454565,
    "flesch_kincaid_grade": 8.929303030303032,
    "composite_score": 0.8360242656724093,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 64.44451689485005,
    "chrf": 82.61752539483027,
    "bertscore_precision": 0.9570074677467346,
    "bertscore_recall": 0.9622756242752075,
    "bertscore_f1": 0.9596342444419861,
    "labse_similarity": 0.9207961559295654,
    "comet_score": 0.9144436120986938,
    "flesch_reading_ease": 63.46072093023258,
    "flesch_kincaid_grade": 8.680790697674421,
    "composite_score": 0.8890312125302778,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 71.1903752950168,
    "chrf": 85.74352306058077,
    "bertscore_precision": 0.976821780204773,
    "bertscore_recall": 0.9756486415863037,
    "bertscore_f1": 0.9762348532676697,
    "labse_similarity": 0.9171895384788513,
    "comet_score": 0.9079013466835022,
    "flesch_reading_ease": 62.29655555555557,
    "flesch_kincaid_grade": 8.887333333333334,
    "composite_score": 0.9030893602328346,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 60.67551962330227,
    "chrf": 81.88156983344791,
    "bertscore_precision": 0.945327877998352,
    "bertscore_recall": 0.9564940333366394,
    "bertscore_f1": 0.9508782029151917,
    "labse_similarity": 0.9216132164001465,
    "comet_score": 0.9021989107131958,
    "flesch_reading_ease": 62.00902250351619,
    "flesch_kincaid_grade": 8.97160337552743,
    "composite_score": 0.8786337062063599,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 53.21775532582997,
    "chrf": 75.65846939333096,
    "bertscore_precision": 0.9568607807159424,
    "bertscore_recall": 0.9597505331039429,
    "bertscore_f1": 0.9583035111427307,
    "labse_similarity": 0.9000611901283264,
    "comet_score": 0.900428295135498,
    "flesch_reading_ease": 60.96588235294121,
    "flesch_kincaid_grade": 8.979084967320262,
    "composite_score": 0.8593158245681853,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 48.13718270163743,
    "chrf": 72.3541401821369,
    "bertscore_precision": 0.9483938217163086,
    "bertscore_recall": 0.9507647752761841,
    "bertscore_f1": 0.949577808380127,
    "labse_similarity": 0.8677712678909302,
    "comet_score": 0.9064183235168457,
    "flesch_reading_ease": 56.552317632850276,
    "flesch_kincaid_grade": 9.43459057971015,
    "composite_score": 0.8417005699462784,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 39.313181798447275,
    "chrf": 69.11917631493915,
    "bertscore_precision": 0.9216451048851013,
    "bertscore_recall": 0.9355701804161072,
    "bertscore_f1": 0.928555428981781,
    "labse_similarity": 0.8809764385223389,
    "comet_score": 0.8731495141983032,
    "flesch_reading_ease": 55.26458624609265,
    "flesch_kincaid_grade": 9.868151747655585,
    "composite_score": 0.8160412412194339,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 54.161360310117885,
    "chrf": 79.9411941120024,
    "bertscore_precision": 0.957149088382721,
    "bertscore_recall": 0.9598608016967773,
    "bertscore_f1": 0.9585030674934387,
    "labse_similarity": 0.9272607564926147,
    "comet_score": 0.912372350692749,
    "flesch_reading_ease": 64.84969184455392,
    "flesch_kincaid_grade": 8.696840722495896,
    "composite_score": 0.8751693106978633,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 63.15272650269886,
    "chrf": 84.7740659552603,
    "bertscore_precision": 0.9608039855957031,
    "bertscore_recall": 0.9600891470909119,
    "bertscore_f1": 0.9604463577270508,
    "labse_similarity": 0.9300132393836975,
    "comet_score": 0.9106826186180115,
    "flesch_reading_ease": 66.8933969795038,
    "flesch_kincaid_grade": 8.478032362459547,
    "composite_score": 0.892121035284947,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 51.8951513640312,
    "chrf": 78.10401147769488,
    "bertscore_precision": 0.9301486015319824,
    "bertscore_recall": 0.9422218799591064,
    "bertscore_f1": 0.9361463189125061,
    "labse_similarity": 0.9157190918922424,
    "comet_score": 0.8964346647262573,
    "flesch_reading_ease": 62.98113725490197,
    "flesch_kincaid_grade": 8.979549019607845,
    "composite_score": 0.8571475488143382,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 50.153369874855336,
    "chrf": 77.19596181336956,
    "bertscore_precision": 0.9431440830230713,
    "bertscore_recall": 0.9494135975837708,
    "bertscore_f1": 0.9462684988975525,
    "labse_similarity": 0.8729248642921448,
    "comet_score": 0.9044649600982666,
    "flesch_reading_ease": 65.15944571615438,
    "flesch_kincaid_grade": 8.87973076084587,
    "composite_score": 0.850529075147171,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 55.35512885904467,
    "chrf": 78.3175970743987,
    "bertscore_precision": 0.9632782936096191,
    "bertscore_recall": 0.9631366729736328,
    "bertscore_f1": 0.963207483291626,
    "labse_similarity": 0.8641999959945679,
    "comet_score": 0.9120009541511536,
    "flesch_reading_ease": 64.37193333333336,
    "flesch_kincaid_grade": 8.421200000000002,
    "composite_score": 0.8626340071948325,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 36.60298561708669,
    "chrf": 68.05354769720975,
    "bertscore_precision": 0.920740008354187,
    "bertscore_recall": 0.9332301616668701,
    "bertscore_f1": 0.9269430041313171,
    "labse_similarity": 0.8640581965446472,
    "comet_score": 0.9007442593574524,
    "flesch_reading_ease": 60.919834262131346,
    "flesch_kincaid_grade": 9.228535040218706,
    "composite_score": 0.8147639125505888,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 68.67821956159123,
    "chrf": 86.36308159686055,
    "bertscore_precision": 0.9496635794639587,
    "bertscore_recall": 0.9551392197608948,
    "bertscore_f1": 0.9523935317993164,
    "labse_similarity": 0.9398016333580017,
    "comet_score": 0.9173552989959717,
    "flesch_reading_ease": 70.08645262602272,
    "flesch_kincaid_grade": 8.132036421219322,
    "composite_score": 0.9012400529172703,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 69.03420110113548,
    "chrf": 84.07719148633763,
    "bertscore_precision": 0.98105788230896,
    "bertscore_recall": 0.9799128770828247,
    "bertscore_f1": 0.9804850816726685,
    "labse_similarity": 0.95284104347229,
    "comet_score": 0.9141089916229248,
    "flesch_reading_ease": 66.26862172594431,
    "flesch_kincaid_grade": 8.465804797353186,
    "composite_score": 0.9083909694326316,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 44.61891628634464,
    "chrf": 75.10979061246157,
    "bertscore_precision": 0.9339786767959595,
    "bertscore_recall": 0.9447665214538574,
    "bertscore_f1": 0.93934166431427,
    "labse_similarity": 0.9309101700782776,
    "comet_score": 0.9067797660827637,
    "flesch_reading_ease": 67.89649425287358,
    "flesch_kincaid_grade": 8.592068965517242,
    "composite_score": 0.8519630770356643,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 0.1555387866681,
    "chrf": 13.649844018979168,
    "bertscore_precision": 0.9606080055236816,
    "bertscore_recall": 0.8667880296707153,
    "bertscore_f1": 0.911289632320404,
    "labse_similarity": 0.9472074508666992,
    "comet_score": 0.721991777420044,
    "flesch_reading_ease": 82.19433333333335,
    "flesch_kincaid_grade": 5.935333333333336,
    "composite_score": 0.6639566290396088,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 74.84785377710605,
    "chrf": 87.5215416846027,
    "bertscore_precision": 0.9863094687461853,
    "bertscore_recall": 0.9863468408584595,
    "bertscore_f1": 0.9863281846046448,
    "labse_similarity": 0.9329583644866943,
    "comet_score": 0.9140839576721191,
    "flesch_reading_ease": 66.43278250544233,
    "flesch_kincaid_grade": 7.912037733359725,
    "composite_score": 0.9171412840007722,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 64.64221004122746,
    "chrf": 84.00603263016552,
    "bertscore_precision": 0.9445704221725464,
    "bertscore_recall": 0.9566258788108826,
    "bertscore_f1": 0.9505599737167358,
    "labse_similarity": 0.9184319972991943,
    "comet_score": 0.9052674770355225,
    "flesch_reading_ease": 66.41495318646737,
    "flesch_kincaid_grade": 8.102848937844218,
    "composite_score": 0.885822519820216,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 47.109087834387864,
    "chrf": 74.34442657801144,
    "bertscore_precision": 0.932338535785675,
    "bertscore_recall": 0.9382778406143188,
    "bertscore_f1": 0.9352987408638,
    "labse_similarity": 0.9029808044433594,
    "comet_score": 0.9049785137176514,
    "flesch_reading_ease": 64.10449308755761,
    "flesch_kincaid_grade": 8.35699436763953,
    "composite_score": 0.8460561392786297,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 56.47491497023502,
    "chrf": 77.42470881660213,
    "bertscore_precision": 0.9681104421615601,
    "bertscore_recall": 0.9670158624649048,
    "bertscore_f1": 0.9675628542900085,
    "labse_similarity": 0.8922130465507507,
    "comet_score": 0.9100751876831055,
    "flesch_reading_ease": 60.78146832162591,
    "flesch_kincaid_grade": 8.572061651776583,
    "composite_score": 0.8688422407130674,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 45.537581239140096,
    "chrf": 72.08247533340739,
    "bertscore_precision": 0.9297813177108765,
    "bertscore_recall": 0.943867564201355,
    "bertscore_f1": 0.9367714524269104,
    "labse_similarity": 0.8447394371032715,
    "comet_score": 0.8960542678833008,
    "flesch_reading_ease": 62.38890594533575,
    "flesch_kincaid_grade": 8.33583569938084,
    "composite_score": 0.8276541843588039,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 59.56325855478809,
    "chrf": 78.9934401496399,
    "bertscore_precision": 0.9313138127326965,
    "bertscore_recall": 0.9427416324615479,
    "bertscore_f1": 0.936992883682251,
    "labse_similarity": 0.8797268867492676,
    "comet_score": 0.8986477851867676,
    "flesch_reading_ease": 62.19444247478279,
    "flesch_kincaid_grade": 8.467138886114721,
    "composite_score": 0.8597586075304685,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 64.6052013375467,
    "chrf": 80.44152959763801,
    "bertscore_precision": 0.9786461591720581,
    "bertscore_recall": 0.9792363047599792,
    "bertscore_f1": 0.9789412021636963,
    "labse_similarity": 0.8772194981575012,
    "comet_score": 0.9112672805786133,
    "flesch_reading_ease": 66.45933732911308,
    "flesch_kincaid_grade": 7.8281958381035786,
    "composite_score": 0.882210576159266,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 47.215448155643884,
    "chrf": 70.959227097638,
    "bertscore_precision": 0.9266748428344727,
    "bertscore_recall": 0.9425879716873169,
    "bertscore_f1": 0.9345636963844299,
    "labse_similarity": 0.8800705671310425,
    "comet_score": 0.8916058540344238,
    "flesch_reading_ease": 59.212470027157735,
    "flesch_kincaid_grade": 8.903098628866662,
    "composite_score": 0.8329389746522444,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 70.82836411471558,
    "chrf": 84.68696128951683,
    "bertscore_precision": 0.9423791170120239,
    "bertscore_recall": 0.9487576484680176,
    "bertscore_f1": 0.9455576539039612,
    "labse_similarity": 0.8967787027359009,
    "comet_score": 0.9095591306686401,
    "flesch_reading_ease": 67.57734860777569,
    "flesch_kincaid_grade": 7.816504186408775,
    "composite_score": 0.8882716254345194,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 78.9550760391392,
    "chrf": 89.5312392089934,
    "bertscore_precision": 0.9845731258392334,
    "bertscore_recall": 0.9843413829803467,
    "bertscore_f1": 0.98445725440979,
    "labse_similarity": 0.903380274772644,
    "comet_score": 0.9172446727752686,
    "flesch_reading_ease": 66.25741403307683,
    "flesch_kincaid_grade": 7.964546422138529,
    "composite_score": 0.9185763343239123,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 67.77066149479239,
    "chrf": 84.36930696265111,
    "bertscore_precision": 0.9467523097991943,
    "bertscore_recall": 0.957575798034668,
    "bertscore_f1": 0.952133297920227,
    "labse_similarity": 0.9035053849220276,
    "comet_score": 0.8998969197273254,
    "flesch_reading_ease": 67.77229511769836,
    "flesch_kincaid_grade": 7.809347573379835,
    "composite_score": 0.8856399182310741,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 52.52210594272508,
    "chrf": 73.53363801744185,
    "bertscore_precision": 0.9270597100257874,
    "bertscore_recall": 0.9392414689064026,
    "bertscore_f1": 0.9331108331680298,
    "labse_similarity": 0.8922816514968872,
    "comet_score": 0.896514892578125,
    "flesch_reading_ease": 61.359595758724595,
    "flesch_kincaid_grade": 8.519472802355889,
    "composite_score": 0.8453408663632055,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 51.515172891233,
    "chrf": 73.70161430670956,
    "bertscore_precision": 0.9605667591094971,
    "bertscore_recall": 0.9622664451599121,
    "bertscore_f1": 0.9614158868789673,
    "labse_similarity": 0.8968911170959473,
    "comet_score": 0.9018042683601379,
    "flesch_reading_ease": 63.34329074151657,
    "flesch_kincaid_grade": 8.126587068845136,
    "composite_score": 0.8553216509242115,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 45.724987704797144,
    "chrf": 70.2411159692021,
    "bertscore_precision": 0.9350621700286865,
    "bertscore_recall": 0.9478117823600769,
    "bertscore_f1": 0.9413937926292419,
    "labse_similarity": 0.8785991668701172,
    "comet_score": 0.8911939859390259,
    "flesch_reading_ease": 64.50456308697427,
    "flesch_kincaid_grade": 8.06077854906765,
    "composite_score": 0.8320231293061527,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 60.59297824574777,
    "chrf": 80.69276826399073,
    "bertscore_precision": 0.947769820690155,
    "bertscore_recall": 0.9549380540847778,
    "bertscore_f1": 0.9513404965400696,
    "labse_similarity": 0.9384598731994629,
    "comet_score": 0.9042004346847534,
    "flesch_reading_ease": 66.71290902483534,
    "flesch_kincaid_grade": 8.133414313549626,
    "composite_score": 0.8807763629148357,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 68.66909605181482,
    "chrf": 83.72183323669734,
    "bertscore_precision": 0.9757995009422302,
    "bertscore_recall": 0.9748648405075073,
    "bertscore_f1": 0.9753319621086121,
    "labse_similarity": 0.9243602752685547,
    "comet_score": 0.9114922285079956,
    "flesch_reading_ease": 63.924791754825705,
    "flesch_kincaid_grade": 8.313941766218548,
    "composite_score": 0.8995965467201543,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 59.8499963380557,
    "chrf": 81.59167416957979,
    "bertscore_precision": 0.9356316328048706,
    "bertscore_recall": 0.9502885341644287,
    "bertscore_f1": 0.9429031610488892,
    "labse_similarity": 0.8918629884719849,
    "comet_score": 0.9044218063354492,
    "flesch_reading_ease": 65.73638299236838,
    "flesch_kincaid_grade": 8.121364714936192,
    "composite_score": 0.8695865051853513,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 37.86003869032177,
    "chrf": 69.09685843849914,
    "bertscore_precision": 0.9095994830131531,
    "bertscore_recall": 0.9230092763900757,
    "bertscore_f1": 0.9162552952766418,
    "labse_similarity": 0.8818851709365845,
    "comet_score": 0.8949143886566162,
    "flesch_reading_ease": 58.69116257526633,
    "flesch_kincaid_grade": 8.784893469198707,
    "composite_score": 0.816487546282534,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 50.58388073052198,
    "chrf": 74.43444304853864,
    "bertscore_precision": 0.9599118232727051,
    "bertscore_recall": 0.9616246223449707,
    "bertscore_f1": 0.9607674479484558,
    "labse_similarity": 0.8900303840637207,
    "comet_score": 0.903430700302124,
    "flesch_reading_ease": 62.67736278447123,
    "flesch_kincaid_grade": 8.117326448651752,
    "composite_score": 0.8543295315761418,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 33.66529799377401,
    "chrf": 63.5790218962629,
    "bertscore_precision": 0.9262822866439819,
    "bertscore_recall": 0.939314603805542,
    "bertscore_f1": 0.9327529072761536,
    "labse_similarity": 0.8601667881011963,
    "comet_score": 0.8853235244750977,
    "flesch_reading_ease": 61.84149147727274,
    "flesch_kincaid_grade": 8.476549873737373,
    "composite_score": 0.8022239417600282,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 63.1407668059802,
    "chrf": 83.9825198272718,
    "bertscore_precision": 0.9378907680511475,
    "bertscore_recall": 0.9478671550750732,
    "bertscore_f1": 0.9428525567054749,
    "labse_similarity": 0.9321282505989075,
    "comet_score": 0.9043869972229004,
    "flesch_reading_ease": 69.3699961503821,
    "flesch_kincaid_grade": 7.509519306197159,
    "composite_score": 0.8844927129840371,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 62.615483253960356,
    "chrf": 80.4350508761641,
    "bertscore_precision": 0.9681985378265381,
    "bertscore_recall": 0.9655615091323853,
    "bertscore_f1": 0.9668782353401184,
    "labse_similarity": 0.9269453287124634,
    "comet_score": 0.8863247036933899,
    "flesch_reading_ease": 67.97556778237474,
    "flesch_kincaid_grade": 7.9332573801598905,
    "composite_score": 0.8803017718360823,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 56.29713333644962,
    "chrf": 79.22337951738312,
    "bertscore_precision": 0.927975058555603,
    "bertscore_recall": 0.9413646459579468,
    "bertscore_f1": 0.9346219301223755,
    "labse_similarity": 0.8768670558929443,
    "comet_score": 0.898800790309906,
    "flesch_reading_ease": 65.55550690158404,
    "flesch_kincaid_grade": 8.366972880119182,
    "composite_score": 0.8555923904053022,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 78.4458897806669,
    "chrf": 88.67185693480485,
    "bertscore_precision": 0.9856364727020264,
    "bertscore_recall": 0.9857387542724609,
    "bertscore_f1": 0.9856876134872437,
    "labse_similarity": 0.9415867924690247,
    "comet_score": 0.9090967178344727,
    "flesch_reading_ease": 81.87615942028987,
    "flesch_kincaid_grade": 4.560124223602486,
    "composite_score": 0.9227514971814703,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 77.81260314529194,
    "chrf": 89.06884118443995,
    "bertscore_precision": 0.9831465482711792,
    "bertscore_recall": 0.9841084480285645,
    "bertscore_f1": 0.9836272597312927,
    "labse_similarity": 0.9432280659675598,
    "comet_score": 0.9069952964782715,
    "flesch_reading_ease": 81.21995033112584,
    "flesch_kincaid_grade": 4.610247555976034,
    "composite_score": 0.9218984801544196,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 67.78172954007638,
    "chrf": 84.83875725053716,
    "bertscore_precision": 0.9526578187942505,
    "bertscore_recall": 0.9658827185630798,
    "bertscore_f1": 0.9592247009277344,
    "labse_similarity": 0.9242300391197205,
    "comet_score": 0.903650164604187,
    "flesch_reading_ease": 80.18817765567766,
    "flesch_kincaid_grade": 4.7659890109890135,
    "composite_score": 0.8935658246691933,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 51.276449799566976,
    "chrf": 74.34842182735643,
    "bertscore_precision": 0.943467915058136,
    "bertscore_recall": 0.950904369354248,
    "bertscore_f1": 0.9471715688705444,
    "labse_similarity": 0.893848717212677,
    "comet_score": 0.9038441181182861,
    "flesch_reading_ease": 77.72148311306904,
    "flesch_kincaid_grade": 5.104128382630588,
    "composite_score": 0.8516813261738719,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 55.870415183361075,
    "chrf": 76.47230564760605,
    "bertscore_precision": 0.9581238031387329,
    "bertscore_recall": 0.9594712257385254,
    "bertscore_f1": 0.958797037601471,
    "labse_similarity": 0.8812053799629211,
    "comet_score": 0.9066437482833862,
    "flesch_reading_ease": 77.03642857142857,
    "flesch_kincaid_grade": 4.998571428571434,
    "composite_score": 0.8611199979986423,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 47.31929285944189,
    "chrf": 73.50295319731019,
    "bertscore_precision": 0.9392315149307251,
    "bertscore_recall": 0.9556041955947876,
    "bertscore_f1": 0.9473471641540527,
    "labse_similarity": 0.8888899683952332,
    "comet_score": 0.9015905261039734,
    "flesch_reading_ease": 78.16730432043678,
    "flesch_kincaid_grade": 4.9159430941256765,
    "composite_score": 0.844953497106663,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 62.872572938969526,
    "chrf": 79.20655399526407,
    "bertscore_precision": 0.9747764468193054,
    "bertscore_recall": 0.9754385352134705,
    "bertscore_f1": 0.9751073718070984,
    "labse_similarity": 0.9058027863502502,
    "comet_score": 0.9121026992797852,
    "flesch_reading_ease": 79.11746376811595,
    "flesch_kincaid_grade": 4.9449068322981375,
    "composite_score": 0.8834008475639915,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 59.124495930808166,
    "chrf": 77.65157315844155,
    "bertscore_precision": 0.969003438949585,
    "bertscore_recall": 0.9697393178939819,
    "bertscore_f1": 0.9693712592124939,
    "labse_similarity": 0.9050922393798828,
    "comet_score": 0.9075474739074707,
    "flesch_reading_ease": 76.93379671150973,
    "flesch_kincaid_grade": 5.166675208199873,
    "composite_score": 0.874318549785063,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 52.30484402887755,
    "chrf": 75.07853523058814,
    "bertscore_precision": 0.9440712928771973,
    "bertscore_recall": 0.9576647877693176,
    "bertscore_f1": 0.9508194923400879,
    "labse_similarity": 0.894928514957428,
    "comet_score": 0.8999239206314087,
    "flesch_reading_ease": 77.34879588839944,
    "flesch_kincaid_grade": 5.156110761485213,
    "composite_score": 0.8541351777261239,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 77.43265074612854,
    "chrf": 88.01594881221831,
    "bertscore_precision": 0.9839882850646973,
    "bertscore_recall": 0.9849495887756348,
    "bertscore_f1": 0.9844686985015869,
    "labse_similarity": 0.9068847894668579,
    "comet_score": 0.9088912010192871,
    "flesch_reading_ease": 82.38955882352944,
    "flesch_kincaid_grade": 4.482600373482729,
    "composite_score": 0.9133969416631254,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 82.62945258476377,
    "chrf": 91.11171476126341,
    "bertscore_precision": 0.9857516288757324,
    "bertscore_recall": 0.9856946468353271,
    "bertscore_f1": 0.9857231378555298,
    "labse_similarity": 0.9151570200920105,
    "comet_score": 0.9103026390075684,
    "flesch_reading_ease": 82.01341760299627,
    "flesch_kincaid_grade": 4.45225521669342,
    "composite_score": 0.925621029853612,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 66.79448171122786,
    "chrf": 85.75526201042312,
    "bertscore_precision": 0.9384888410568237,
    "bertscore_recall": 0.9524531364440918,
    "bertscore_f1": 0.945419430732727,
    "labse_similarity": 0.8575195074081421,
    "comet_score": 0.887497067451477,
    "flesch_reading_ease": 80.5565566037736,
    "flesch_kincaid_grade": 4.844736448038336,
    "composite_score": 0.8724313722911783,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 52.96697349543021,
    "chrf": 73.41683460918009,
    "bertscore_precision": 0.9607306122779846,
    "bertscore_recall": 0.962646484375,
    "bertscore_f1": 0.9616876244544983,
    "labse_similarity": 0.9127514958381653,
    "comet_score": 0.9005128145217896,
    "flesch_reading_ease": 76.28422619047622,
    "flesch_kincaid_grade": 5.269107142857145,
    "composite_score": 0.8592770155436303,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 50.80358537264597,
    "chrf": 73.30051879885634,
    "bertscore_precision": 0.9542887210845947,
    "bertscore_recall": 0.9541016221046448,
    "bertscore_f1": 0.9541952013969421,
    "labse_similarity": 0.929939329624176,
    "comet_score": 0.9047907590866089,
    "flesch_reading_ease": 74.2125,
    "flesch_kincaid_grade": 5.410197568389059,
    "composite_score": 0.8591984796865004,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 42.55376534735664,
    "chrf": 67.74087876496256,
    "bertscore_precision": 0.9329546689987183,
    "bertscore_recall": 0.9491162896156311,
    "bertscore_f1": 0.9409660696983337,
    "labse_similarity": 0.9039483666419983,
    "comet_score": 0.887588620185852,
    "flesch_reading_ease": 75.77938811188811,
    "flesch_kincaid_grade": 5.227137862137862,
    "composite_score": 0.8291417327791634,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 70.70803720591871,
    "chrf": 83.72504209764108,
    "bertscore_precision": 0.9778723120689392,
    "bertscore_recall": 0.9782673716545105,
    "bertscore_f1": 0.9780697822570801,
    "labse_similarity": 0.9352583885192871,
    "comet_score": 0.9083656072616577,
    "flesch_reading_ease": 81.95441558441561,
    "flesch_kincaid_grade": 4.56103896103896,
    "composite_score": 0.9038596145487761,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 63.44963941831042,
    "chrf": 79.66812249966388,
    "bertscore_precision": 0.9710860252380371,
    "bertscore_recall": 0.9704710245132446,
    "bertscore_f1": 0.9707784056663513,
    "labse_similarity": 0.9367696642875671,
    "comet_score": 0.9086158275604248,
    "flesch_reading_ease": 76.55248481397118,
    "flesch_kincaid_grade": 5.178455906280508,
    "composite_score": 0.8886932346153312,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 49.53070419080197,
    "chrf": 76.3159552420064,
    "bertscore_precision": 0.9299741983413696,
    "bertscore_recall": 0.9443951845169067,
    "bertscore_f1": 0.9371292591094971,
    "labse_similarity": 0.9202134013175964,
    "comet_score": 0.8936542272567749,
    "flesch_reading_ease": 78.5673563218391,
    "flesch_kincaid_grade": 5.045295566502464,
    "composite_score": 0.8525996518643737,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 50.472491807684676,
    "chrf": 74.09266689399456,
    "bertscore_precision": 0.9432533979415894,
    "bertscore_recall": 0.950916051864624,
    "bertscore_f1": 0.9470692276954651,
    "labse_similarity": 0.9124878644943237,
    "comet_score": 0.8975081443786621,
    "flesch_reading_ease": 77.38749642346212,
    "flesch_kincaid_grade": 5.221692213366033,
    "composite_score": 0.8526068694508463,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 51.0440708280737,
    "chrf": 74.21962141323752,
    "bertscore_precision": 0.9561156034469604,
    "bertscore_recall": 0.9560208320617676,
    "bertscore_f1": 0.956068217754364,
    "labse_similarity": 0.9127423167228699,
    "comet_score": 0.9039994478225708,
    "flesch_reading_ease": 75.6517391304348,
    "flesch_kincaid_grade": 5.1562180814354726,
    "composite_score": 0.8577422935744557,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 46.77605149685052,
    "chrf": 72.13507672443603,
    "bertscore_precision": 0.9367971420288086,
    "bertscore_recall": 0.9524959921836853,
    "bertscore_f1": 0.9445813298225403,
    "labse_similarity": 0.8949843049049377,
    "comet_score": 0.8955904245376587,
    "flesch_reading_ease": 78.85491379310348,
    "flesch_kincaid_grade": 4.833653530377671,
    "composite_score": 0.8412475326456689,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 68.2623833607774,
    "chrf": 84.736558538393,
    "bertscore_precision": 0.9717384576797485,
    "bertscore_recall": 0.9708718657493591,
    "bertscore_f1": 0.9713050127029419,
    "labse_similarity": 0.9400674104690552,
    "comet_score": 0.8959736824035645,
    "flesch_reading_ease": 83.19232203969884,
    "flesch_kincaid_grade": 4.536249633323557,
    "composite_score": 0.8987656276739516,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 74.32708697243514,
    "chrf": 86.26810230050904,
    "bertscore_precision": 0.984682023525238,
    "bertscore_recall": 0.9842782020568848,
    "bertscore_f1": 0.9844800233840942,
    "labse_similarity": 0.9425476789474487,
    "comet_score": 0.9103370308876038,
    "flesch_reading_ease": 83.0531168831169,
    "flesch_kincaid_grade": 4.407792207792209,
    "composite_score": 0.9151670409498176,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 57.81045280541725,
    "chrf": 80.66869844722615,
    "bertscore_precision": 0.9347485303878784,
    "bertscore_recall": 0.9476974010467529,
    "bertscore_f1": 0.9411784410476685,
    "labse_similarity": 0.9174764752388,
    "comet_score": 0.8948614001274109,
    "flesch_reading_ease": 82.20188543754176,
    "flesch_kincaid_grade": 4.745375035785859,
    "composite_score": 0.8683776778701697,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 80.60353549880477,
    "chrf": 89.57038824388832,
    "bertscore_precision": 0.9549291133880615,
    "bertscore_recall": 0.9610457420349121,
    "bertscore_f1": 0.9579776525497437,
    "labse_similarity": 0.9384921789169312,
    "comet_score": 0.9170235395431519,
    "flesch_reading_ease": 75.86550720949958,
    "flesch_kincaid_grade": 5.570417302798983,
    "composite_score": 0.9193067342987344,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 78.99075377829637,
    "chrf": 88.76645057940729,
    "bertscore_precision": 0.9838847517967224,
    "bertscore_recall": 0.9847191572189331,
    "bertscore_f1": 0.9843018054962158,
    "labse_similarity": 0.9401505589485168,
    "comet_score": 0.9196351766586304,
    "flesch_reading_ease": 74.50022743055557,
    "flesch_kincaid_grade": 5.694598958333337,
    "composite_score": 0.9253698772506329,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 78.56304606129812,
    "chrf": 90.09460156507002,
    "bertscore_precision": 0.9452327489852905,
    "bertscore_recall": 0.9574851989746094,
    "bertscore_f1": 0.9513195157051086,
    "labse_similarity": 0.9183461666107178,
    "comet_score": 0.9146295785903931,
    "flesch_reading_ease": 76.79255534310603,
    "flesch_kincaid_grade": 5.435592096876995,
    "composite_score": 0.9114274310901775,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 63.05258349821734,
    "chrf": 80.28464224857838,
    "bertscore_precision": 0.9676061868667603,
    "bertscore_recall": 0.9661546945571899,
    "bertscore_f1": 0.9668799042701721,
    "labse_similarity": 0.8950888514518738,
    "comet_score": 0.9053545594215393,
    "flesch_reading_ease": 79.98039166869083,
    "flesch_kincaid_grade": 5.003794429600845,
    "composite_score": 0.878899928297896,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 54.80452467835707,
    "chrf": 76.68084879441314,
    "bertscore_precision": 0.9666876792907715,
    "bertscore_recall": 0.9668667316436768,
    "bertscore_f1": 0.9667772054672241,
    "labse_similarity": 0.8796919584274292,
    "comet_score": 0.9126430749893188,
    "flesch_reading_ease": 68.85717723199473,
    "flesch_kincaid_grade": 6.4850514437437745,
    "composite_score": 0.8639581199429596,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 44.3939025976432,
    "chrf": 72.30864126558446,
    "bertscore_precision": 0.9221194982528687,
    "bertscore_recall": 0.9370684027671814,
    "bertscore_f1": 0.9295338988304138,
    "labse_similarity": 0.8558517098426819,
    "comet_score": 0.9051531553268433,
    "flesch_reading_ease": 69.49315299279742,
    "flesch_kincaid_grade": 6.283277589204403,
    "composite_score": 0.8291756649453913,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 65.20357772522296,
    "chrf": 81.61965534952806,
    "bertscore_precision": 0.9739202260971069,
    "bertscore_recall": 0.9735794067382812,
    "bertscore_f1": 0.9737497568130493,
    "labse_similarity": 0.885935366153717,
    "comet_score": 0.9126452207565308,
    "flesch_reading_ease": 76.954314425324,
    "flesch_kincaid_grade": 5.4130299553856,
    "composite_score": 0.8851063662133061,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 62.50080813308644,
    "chrf": 78.29934543881613,
    "bertscore_precision": 0.9723755121231079,
    "bertscore_recall": 0.973783016204834,
    "bertscore_f1": 0.9730787873268127,
    "labse_similarity": 0.8816571235656738,
    "comet_score": 0.9117896556854248,
    "flesch_reading_ease": 75.06559259259261,
    "flesch_kincaid_grade": 5.472205761316875,
    "composite_score": 0.8761523011238453,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 51.980626200378474,
    "chrf": 73.15801400810173,
    "bertscore_precision": 0.9381669759750366,
    "bertscore_recall": 0.9496407508850098,
    "bertscore_f1": 0.9438689947128296,
    "labse_similarity": 0.8665181398391724,
    "comet_score": 0.9080876111984253,
    "flesch_reading_ease": 74.46843020238715,
    "flesch_kincaid_grade": 5.473040996367413,
    "composite_score": 0.8452038763938207,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 76.49936917636984,
    "chrf": 87.12125164917154,
    "bertscore_precision": 0.9590696692466736,
    "bertscore_recall": 0.9646836519241333,
    "bertscore_f1": 0.9618685245513916,
    "labse_similarity": 0.9195144772529602,
    "comet_score": 0.9157166481018066,
    "flesch_reading_ease": 77.02832323232325,
    "flesch_kincaid_grade": 5.3695834945196665,
    "composite_score": 0.9085738614915884,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 79.2016003200112,
    "chrf": 89.2933102637443,
    "bertscore_precision": 0.9831280708312988,
    "bertscore_recall": 0.9840668439865112,
    "bertscore_f1": 0.9835972189903259,
    "labse_similarity": 0.9205766320228577,
    "comet_score": 0.918531060218811,
    "flesch_reading_ease": 75.64245109780443,
    "flesch_kincaid_grade": 5.4745548902195615,
    "composite_score": 0.9219688228719997,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 73.59822504423525,
    "chrf": 86.79671451549143,
    "bertscore_precision": 0.9500628113746643,
    "bertscore_recall": 0.9622699618339539,
    "bertscore_f1": 0.956127405166626,
    "labse_similarity": 0.9063215851783752,
    "comet_score": 0.9097139835357666,
    "flesch_reading_ease": 76.79200000000003,
    "flesch_kincaid_grade": 5.330777777777776,
    "composite_score": 0.8993243312870769,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 55.69298833415874,
    "chrf": 76.21412944917806,
    "bertscore_precision": 0.961802065372467,
    "bertscore_recall": 0.9602689743041992,
    "bertscore_f1": 0.9610349535942078,
    "labse_similarity": 0.9063761830329895,
    "comet_score": 0.8994959592819214,
    "flesch_reading_ease": 75.60715942028988,
    "flesch_kincaid_grade": 5.761028985507249,
    "composite_score": 0.8644738950132664,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 49.11988788801474,
    "chrf": 70.6026115264534,
    "bertscore_precision": 0.9563543796539307,
    "bertscore_recall": 0.957551121711731,
    "bertscore_f1": 0.9569523334503174,
    "labse_similarity": 0.9268994927406311,
    "comet_score": 0.905971884727478,
    "flesch_reading_ease": 68.84331772268139,
    "flesch_kincaid_grade": 6.3290468319559245,
    "composite_score": 0.8539823749427857,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 48.355806208731046,
    "chrf": 71.02196724516583,
    "bertscore_precision": 0.9324027299880981,
    "bertscore_recall": 0.944833517074585,
    "bertscore_f1": 0.9385769963264465,
    "labse_similarity": 0.8861194252967834,
    "comet_score": 0.9095703363418579,
    "flesch_reading_ease": 72.10325770367244,
    "flesch_kincaid_grade": 5.983682988602791,
    "composite_score": 0.8410783251192349,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 69.74569527824342,
    "chrf": 86.38972176207102,
    "bertscore_precision": 0.9668794870376587,
    "bertscore_recall": 0.9665004014968872,
    "bertscore_f1": 0.966689944267273,
    "labse_similarity": 0.9221565127372742,
    "comet_score": 0.8858582973480225,
    "flesch_reading_ease": 71.84567067530067,
    "flesch_kincaid_grade": 6.156005242059823,
    "composite_score": 0.8952331380859924,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 60.088758663503036,
    "chrf": 80.78341407158814,
    "bertscore_precision": 0.9646917581558228,
    "bertscore_recall": 0.9663508534431458,
    "bertscore_f1": 0.9655205607414246,
    "labse_similarity": 0.8958364725112915,
    "comet_score": 0.909900426864624,
    "flesch_reading_ease": 69.98735884133161,
    "flesch_kincaid_grade": 6.335094682230871,
    "composite_score": 0.8775624492117269,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 61.995737357173994,
    "chrf": 82.35928734961176,
    "bertscore_precision": 0.9368010759353638,
    "bertscore_recall": 0.9501782655715942,
    "bertscore_f1": 0.9434422254562378,
    "labse_similarity": 0.8989648818969727,
    "comet_score": 0.908117949962616,
    "flesch_reading_ease": 74.42169700697008,
    "flesch_kincaid_grade": 5.87117097170972,
    "composite_score": 0.8753897998885114,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 54.2115678553612,
    "chrf": 78.25069434604556,
    "bertscore_precision": 0.9294010996818542,
    "bertscore_recall": 0.9378273487091064,
    "bertscore_f1": 0.9335951805114746,
    "labse_similarity": 0.8839511275291443,
    "comet_score": 0.9032065868377686,
    "flesch_reading_ease": 71.89781326034066,
    "flesch_kincaid_grade": 6.067244525547444,
    "composite_score": 0.8542580357431429,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 59.37719924212222,
    "chrf": 78.83232198088427,
    "bertscore_precision": 0.9697291851043701,
    "bertscore_recall": 0.9695503115653992,
    "bertscore_f1": 0.9696397185325623,
    "labse_similarity": 0.9058998227119446,
    "comet_score": 0.9093441963195801,
    "flesch_reading_ease": 69.58257109964612,
    "flesch_kincaid_grade": 6.191520061399395,
    "composite_score": 0.8770336113955013,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 43.23101816198379,
    "chrf": 71.7042340724829,
    "bertscore_precision": 0.9277743101119995,
    "bertscore_recall": 0.9410332441329956,
    "bertscore_f1": 0.9343567490577698,
    "labse_similarity": 0.8718621730804443,
    "comet_score": 0.8839308023452759,
    "flesch_reading_ease": 69.05294612216886,
    "flesch_kincaid_grade": 6.249535003431706,
    "composite_score": 0.8264495291904469,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 72.48106610197786,
    "chrf": 86.50039731290897,
    "bertscore_precision": 0.9477964639663696,
    "bertscore_recall": 0.9534754753112793,
    "bertscore_f1": 0.9506275057792664,
    "labse_similarity": 0.9295132756233215,
    "comet_score": 0.9062443971633911,
    "flesch_reading_ease": 78.5508071895425,
    "flesch_kincaid_grade": 5.306284313725492,
    "composite_score": 0.8998836682206333,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 85.09364899599737,
    "chrf": 91.29701227598713,
    "bertscore_precision": 0.9903424382209778,
    "bertscore_recall": 0.9901479482650757,
    "bertscore_f1": 0.9902451634407043,
    "labse_similarity": 0.9291971921920776,
    "comet_score": 0.9207035303115845,
    "flesch_reading_ease": 77.72107843137258,
    "flesch_kincaid_grade": 5.2343137254902,
    "composite_score": 0.935128037458501,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 51.25746634394964,
    "chrf": 72.25340050939852,
    "bertscore_precision": 0.9232495427131653,
    "bertscore_recall": 0.9345732927322388,
    "bertscore_f1": 0.9288768768310547,
    "labse_similarity": 0.9036617875099182,
    "comet_score": 0.8727602958679199,
    "flesch_reading_ease": 75.3455232395771,
    "flesch_kincaid_grade": 5.825125074805509,
    "composite_score": 0.8372230616263274,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 79.7193051043928,
    "chrf": 89.41399112163846,
    "bertscore_precision": 0.9501694440841675,
    "bertscore_recall": 0.9607933163642883,
    "bertscore_f1": 0.9554517865180969,
    "labse_similarity": 0.9353103041648865,
    "comet_score": 0.9242580533027649,
    "flesch_reading_ease": 63.50430058651027,
    "flesch_kincaid_grade": 8.88248826979472,
    "composite_score": 0.9186024019009481,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 83.64374450802305,
    "chrf": 91.22644106116505,
    "bertscore_precision": 0.992242693901062,
    "bertscore_recall": 0.9915481805801392,
    "bertscore_f1": 0.991895318031311,
    "labse_similarity": 0.9276413321495056,
    "comet_score": 0.9256668090820312,
    "flesch_reading_ease": 61.403281669150545,
    "flesch_kincaid_grade": 9.10326825633383,
    "composite_score": 0.9349969702095728,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 62.75103908996275,
    "chrf": 83.0684891538521,
    "bertscore_precision": 0.9273239374160767,
    "bertscore_recall": 0.9439513683319092,
    "bertscore_f1": 0.9355637431144714,
    "labse_similarity": 0.9218509793281555,
    "comet_score": 0.9042187929153442,
    "flesch_reading_ease": 61.86220588235294,
    "flesch_kincaid_grade": 9.155728291316532,
    "composite_score": 0.8784477898495494,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 50.058759694821376,
    "chrf": 74.23314487703944,
    "bertscore_precision": 0.914953351020813,
    "bertscore_recall": 0.9314905405044556,
    "bertscore_f1": 0.9231478571891785,
    "labse_similarity": 0.9052881002426147,
    "comet_score": 0.88612961769104,
    "flesch_reading_ease": 52.32602981029814,
    "flesch_kincaid_grade": 10.487804878048781,
    "composite_score": 0.8409428586384171,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 62.62393644828379,
    "chrf": 81.42841844339776,
    "bertscore_precision": 0.9757317900657654,
    "bertscore_recall": 0.9749577641487122,
    "bertscore_f1": 0.9753445982933044,
    "labse_similarity": 0.9123048186302185,
    "comet_score": 0.915324330329895,
    "flesch_reading_ease": 58.465108327625046,
    "flesch_kincaid_grade": 9.300791466875427,
    "composite_score": 0.8886619899098892,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 50.537387082067745,
    "chrf": 77.0458235074589,
    "bertscore_precision": 0.9157065153121948,
    "bertscore_recall": 0.9302505254745483,
    "bertscore_f1": 0.9229211807250977,
    "labse_similarity": 0.8837011456489563,
    "comet_score": 0.9046313762664795,
    "flesch_reading_ease": 60.73340490739872,
    "flesch_kincaid_grade": 9.156050766193477,
    "composite_score": 0.8458805497571965,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 63.896654383005426,
    "chrf": 82.11438133462124,
    "bertscore_precision": 0.9421887397766113,
    "bertscore_recall": 0.9532203674316406,
    "bertscore_f1": 0.947672426700592,
    "labse_similarity": 0.9155054092407227,
    "comet_score": 0.9237186312675476,
    "flesch_reading_ease": 63.225875870691226,
    "flesch_kincaid_grade": 9.038761564565103,
    "composite_score": 0.8854006940601463,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 71.07546901764772,
    "chrf": 83.7610854343257,
    "bertscore_precision": 0.9823936223983765,
    "bertscore_recall": 0.9829137325286865,
    "bertscore_f1": 0.9826536178588867,
    "labse_similarity": 0.905270516872406,
    "comet_score": 0.9190278053283691,
    "flesch_reading_ease": 57.81267468710587,
    "flesch_kincaid_grade": 9.427927816047347,
    "composite_score": 0.9023242372333757,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 58.7378941234074,
    "chrf": 76.10571043809826,
    "bertscore_precision": 0.9143399000167847,
    "bertscore_recall": 0.9311851859092712,
    "bertscore_f1": 0.9226856827735901,
    "labse_similarity": 0.8910519480705261,
    "comet_score": 0.8853901624679565,
    "flesch_reading_ease": 53.83596115164664,
    "flesch_kincaid_grade": 9.914846381384343,
    "composite_score": 0.8492600948437261,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 74.74578288259562,
    "chrf": 87.04589162019738,
    "bertscore_precision": 0.9413384199142456,
    "bertscore_recall": 0.9522510766983032,
    "bertscore_f1": 0.946763277053833,
    "labse_similarity": 0.9117644429206848,
    "comet_score": 0.9166489839553833,
    "flesch_reading_ease": 64.80569923706226,
    "flesch_kincaid_grade": 8.687418696571378,
    "composite_score": 0.9008587380020244,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 76.93183368158446,
    "chrf": 87.62275514570067,
    "bertscore_precision": 0.9804850816726685,
    "bertscore_recall": 0.9811626672744751,
    "bertscore_f1": 0.9808237552642822,
    "labse_similarity": 0.9063575863838196,
    "comet_score": 0.9204830527305603,
    "flesch_reading_ease": 61.68202594677098,
    "flesch_kincaid_grade": 8.960501001621676,
    "composite_score": 0.914005373438824,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 69.91368834858477,
    "chrf": 86.1111521013181,
    "bertscore_precision": 0.9333689212799072,
    "bertscore_recall": 0.9510854482650757,
    "bertscore_f1": 0.9421439170837402,
    "labse_similarity": 0.8990224599838257,
    "comet_score": 0.9074904322624207,
    "flesch_reading_ease": 61.66332265275709,
    "flesch_kincaid_grade": 9.066997764530555,
    "composite_score": 0.8884006916880544,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 57.985122816450314,
    "chrf": 77.15716506392653,
    "bertscore_precision": 0.9451836347579956,
    "bertscore_recall": 0.9563409686088562,
    "bertscore_f1": 0.9507296085357666,
    "labse_similarity": 0.9038799405097961,
    "comet_score": 0.9187894463539124,
    "flesch_reading_ease": 61.01173228644407,
    "flesch_kincaid_grade": 9.090128464667487,
    "composite_score": 0.8694131026635075,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 72.6680120014206,
    "chrf": 84.87867611185696,
    "bertscore_precision": 0.9777275323867798,
    "bertscore_recall": 0.9785935878753662,
    "bertscore_f1": 0.9781603813171387,
    "labse_similarity": 0.9039247632026672,
    "comet_score": 0.9198223352432251,
    "flesch_reading_ease": 65.15000949796475,
    "flesch_kincaid_grade": 8.409033921302576,
    "composite_score": 0.9041746770156872,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 44.30364055846262,
    "chrf": 68.1558819599012,
    "bertscore_precision": 0.9222198128700256,
    "bertscore_recall": 0.9429800510406494,
    "bertscore_f1": 0.9324843883514404,
    "labse_similarity": 0.892096757888794,
    "comet_score": 0.8957542181015015,
    "flesch_reading_ease": 58.391458098904366,
    "flesch_kincaid_grade": 9.27492922712467,
    "composite_score": 0.8286406861068807,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 64.86861637364142,
    "chrf": 83.17439579114657,
    "bertscore_precision": 0.9358513355255127,
    "bertscore_recall": 0.947913646697998,
    "bertscore_f1": 0.9418438673019409,
    "labse_similarity": 0.9265420436859131,
    "comet_score": 0.9188312292098999,
    "flesch_reading_ease": 62.56944551773948,
    "flesch_kincaid_grade": 9.080634828924804,
    "composite_score": 0.8871995862906009,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 70.25437217162613,
    "chrf": 84.49372531468086,
    "bertscore_precision": 0.9826501607894897,
    "bertscore_recall": 0.9815500974655151,
    "bertscore_f1": 0.9820997714996338,
    "labse_similarity": 0.9294071197509766,
    "comet_score": 0.9222992062568665,
    "flesch_reading_ease": 60.58063219349458,
    "flesch_kincaid_grade": 9.240595681586509,
    "composite_score": 0.9080811171079495,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 58.5944375152487,
    "chrf": 79.98186490590099,
    "bertscore_precision": 0.9296789169311523,
    "bertscore_recall": 0.9447437524795532,
    "bertscore_f1": 0.937150776386261,
    "labse_similarity": 0.9254682660102844,
    "comet_score": 0.903601884841919,
    "flesch_reading_ease": 60.074986013986035,
    "flesch_kincaid_grade": 9.34274125874126,
    "composite_score": 0.8707065922025151,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 45.34266813215168,
    "chrf": 72.31658750315191,
    "bertscore_precision": 0.9223246574401855,
    "bertscore_recall": 0.9247251749038696,
    "bertscore_f1": 0.9235233068466187,
    "labse_similarity": 0.8946060538291931,
    "comet_score": 0.8625805377960205,
    "flesch_reading_ease": 50.56675369093088,
    "flesch_kincaid_grade": 10.86078777860115,
    "composite_score": 0.8254408866557089,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 60.65202902615032,
    "chrf": 80.42399174497609,
    "bertscore_precision": 0.9711551070213318,
    "bertscore_recall": 0.9709901213645935,
    "bertscore_f1": 0.9710726141929626,
    "labse_similarity": 0.9038833975791931,
    "comet_score": 0.9176673293113708,
    "flesch_reading_ease": 59.43724168514413,
    "flesch_kincaid_grade": 9.228434589800443,
    "composite_score": 0.8828033127451846,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 44.699119900536395,
    "chrf": 71.29408894154263,
    "bertscore_precision": 0.9201271533966064,
    "bertscore_recall": 0.9351890683174133,
    "bertscore_f1": 0.9275970458984375,
    "labse_similarity": 0.8921921849250793,
    "comet_score": 0.9009482860565186,
    "flesch_reading_ease": 57.834170171749065,
    "flesch_kincaid_grade": 9.567712933753942,
    "composite_score": 0.8335948755815271,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 70.21691490998371,
    "chrf": 85.06958942939613,
    "bertscore_precision": 0.9374105334281921,
    "bertscore_recall": 0.9489960670471191,
    "bertscore_f1": 0.9431676864624023,
    "labse_similarity": 0.9335296750068665,
    "comet_score": 0.9117246270179749,
    "flesch_reading_ease": 64.22005141433911,
    "flesch_kincaid_grade": 8.918161537093045,
    "composite_score": 0.8954086967486655,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 72.14414570763645,
    "chrf": 86.11321299309672,
    "bertscore_precision": 0.9750897884368896,
    "bertscore_recall": 0.9752342700958252,
    "bertscore_f1": 0.9751620292663574,
    "labse_similarity": 0.9287005066871643,
    "comet_score": 0.9184500575065613,
    "flesch_reading_ease": 63.49523946784923,
    "flesch_kincaid_grade": 8.847617147080562,
    "composite_score": 0.909215189691262,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 57.066889385166306,
    "chrf": 79.38195179866307,
    "bertscore_precision": 0.9213533401489258,
    "bertscore_recall": 0.9369862079620361,
    "bertscore_f1": 0.9291040301322937,
    "labse_similarity": 0.919269859790802,
    "comet_score": 0.899350106716156,
    "flesch_reading_ease": 63.65696542893727,
    "flesch_kincaid_grade": 9.190926163038839,
    "composite_score": 0.8635625247600485,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 71.81404868485902,
    "chrf": 88.39215101503764,
    "bertscore_precision": 0.9557973146438599,
    "bertscore_recall": 0.9660245180130005,
    "bertscore_f1": 0.9608836770057678,
    "labse_similarity": 0.9372446537017822,
    "comet_score": 0.9194793701171875,
    "flesch_reading_ease": 59.954837398373996,
    "flesch_kincaid_grade": 8.777038327526135,
    "composite_score": 0.909986151578799,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 74.52624357270767,
    "chrf": 88.61997034767923,
    "bertscore_precision": 0.9833350777626038,
    "bertscore_recall": 0.986294150352478,
    "bertscore_f1": 0.9848123788833618,
    "labse_similarity": 0.9339429140090942,
    "comet_score": 0.916488528251648,
    "flesch_reading_ease": 55.17601449275364,
    "flesch_kincaid_grade": 9.372608695652175,
    "composite_score": 0.9188106276239659,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 69.01001764230512,
    "chrf": 86.75102804940099,
    "bertscore_precision": 0.9593977928161621,
    "bertscore_recall": 0.9738267660140991,
    "bertscore_f1": 0.9665584564208984,
    "labse_similarity": 0.9433317184448242,
    "comet_score": 0.9200882911682129,
    "flesch_reading_ease": 57.26269230769233,
    "flesch_kincaid_grade": 8.963260073260074,
    "composite_score": 0.9077925131236941,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 49.26954230750412,
    "chrf": 78.427524413655,
    "bertscore_precision": 0.9396908283233643,
    "bertscore_recall": 0.9496686458587646,
    "bertscore_f1": 0.9446533918380737,
    "labse_similarity": 0.9039930105209351,
    "comet_score": 0.9092143177986145,
    "flesch_reading_ease": 47.957435897435914,
    "flesch_kincaid_grade": 10.414945054945054,
    "composite_score": 0.8584090280332493,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 44.780899335300916,
    "chrf": 74.84543943166429,
    "bertscore_precision": 0.9716449975967407,
    "bertscore_recall": 0.9716010093688965,
    "bertscore_f1": 0.9716230034828186,
    "labse_similarity": 0.8982048034667969,
    "comet_score": 0.9098018407821655,
    "flesch_reading_ease": 44.72852713178298,
    "flesch_kincaid_grade": 10.581395348837212,
    "composite_score": 0.8556273804165436,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 49.32167163757955,
    "chrf": 79.01120854052661,
    "bertscore_precision": 0.9468169212341309,
    "bertscore_recall": 0.9629462361335754,
    "bertscore_f1": 0.954813539981842,
    "labse_similarity": 0.8935158848762512,
    "comet_score": 0.9075835943222046,
    "flesch_reading_ease": 50.908415300546466,
    "flesch_kincaid_grade": 9.766744730679157,
    "composite_score": 0.8598816219987233,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 62.58411764286549,
    "chrf": 84.07258598325782,
    "bertscore_precision": 0.9554170966148376,
    "bertscore_recall": 0.9650280475616455,
    "bertscore_f1": 0.9601984620094299,
    "labse_similarity": 0.8859290480613708,
    "comet_score": 0.9141240119934082,
    "flesch_reading_ease": 59.142355415352284,
    "flesch_kincaid_grade": 8.7602343397927,
    "composite_score": 0.8824693478312075,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 56.80032741088637,
    "chrf": 80.72532713461484,
    "bertscore_precision": 0.9761219024658203,
    "bertscore_recall": 0.9783819913864136,
    "bertscore_f1": 0.9772506356239319,
    "labse_similarity": 0.8844369649887085,
    "comet_score": 0.9125343561172485,
    "flesch_reading_ease": 50.33541535226081,
    "flesch_kincaid_grade": 9.988625506985134,
    "composite_score": 0.876084490827042,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 43.12864407095136,
    "chrf": 75.38861585232215,
    "bertscore_precision": 0.945836067199707,
    "bertscore_recall": 0.958573043346405,
    "bertscore_f1": 0.952161967754364,
    "labse_similarity": 0.887935221195221,
    "comet_score": 0.9035454988479614,
    "flesch_reading_ease": 49.40084905660379,
    "flesch_kincaid_grade": 10.130808625336929,
    "composite_score": 0.8453335771267784,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 63.787262256777495,
    "chrf": 85.1568476436054,
    "bertscore_precision": 0.9495998620986938,
    "bertscore_recall": 0.9609137177467346,
    "bertscore_f1": 0.9552232623100281,
    "labse_similarity": 0.9052019715309143,
    "comet_score": 0.9135738611221313,
    "flesch_reading_ease": 59.22756493506495,
    "flesch_kincaid_grade": 8.713397347333519,
    "composite_score": 0.8875233720019098,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 60.52561455662285,
    "chrf": 81.41202485493422,
    "bertscore_precision": 0.9803495407104492,
    "bertscore_recall": 0.9772999286651611,
    "bertscore_f1": 0.9788223505020142,
    "labse_similarity": 0.9063754677772522,
    "comet_score": 0.9113273620605469,
    "flesch_reading_ease": 53.84388377445339,
    "flesch_kincaid_grade": 9.317514384349828,
    "composite_score": 0.8853972910602156,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 47.85925591031164,
    "chrf": 78.97363207525339,
    "bertscore_precision": 0.9384615421295166,
    "bertscore_recall": 0.9513555765151978,
    "bertscore_f1": 0.9448645710945129,
    "labse_similarity": 0.881965160369873,
    "comet_score": 0.8825277090072632,
    "flesch_reading_ease": 56.783431372549046,
    "flesch_kincaid_grade": 9.361344537815125,
    "composite_score": 0.8468040346773359,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 54.29154153737877,
    "chrf": 73.99139720812681,
    "bertscore_precision": 0.9406634569168091,
    "bertscore_recall": 0.9497566223144531,
    "bertscore_f1": 0.9451881647109985,
    "labse_similarity": 0.8790061473846436,
    "comet_score": 0.9046576619148254,
    "flesch_reading_ease": 49.26745036572623,
    "flesch_kincaid_grade": 10.161244961934617,
    "composite_score": 0.8508007317185037,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 53.39657431533687,
    "chrf": 77.15954284664201,
    "bertscore_precision": 0.9782848358154297,
    "bertscore_recall": 0.9745651483535767,
    "bertscore_f1": 0.9764214158058167,
    "labse_similarity": 0.8741596937179565,
    "comet_score": 0.9112601280212402,
    "flesch_reading_ease": 48.84175317185699,
    "flesch_kincaid_grade": 9.865724172021753,
    "composite_score": 0.864709284075946,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 32.45134203961713,
    "chrf": 66.34340493067148,
    "bertscore_precision": 0.9314368963241577,
    "bertscore_recall": 0.9442815780639648,
    "bertscore_f1": 0.937815248966217,
    "labse_similarity": 0.8634432554244995,
    "comet_score": 0.9046204090118408,
    "flesch_reading_ease": 47.399768664563624,
    "flesch_kincaid_grade": 10.39808922938261,
    "composite_score": 0.8121547774633495,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 57.553722860098226,
    "chrf": 82.3447618655217,
    "bertscore_precision": 0.9399687051773071,
    "bertscore_recall": 0.94920814037323,
    "bertscore_f1": 0.9445657730102539,
    "labse_similarity": 0.8666797280311584,
    "comet_score": 0.8975027203559875,
    "flesch_reading_ease": 59.386168373879656,
    "flesch_kincaid_grade": 8.98487195902689,
    "composite_score": 0.8621522232566854,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 69.3375825696995,
    "chrf": 85.03796249413172,
    "bertscore_precision": 0.9856047630310059,
    "bertscore_recall": 0.9861133098602295,
    "bertscore_f1": 0.9858589768409729,
    "labse_similarity": 0.8939544558525085,
    "comet_score": 0.9182527661323547,
    "flesch_reading_ease": 49.80485436893207,
    "flesch_kincaid_grade": 9.967988904299585,
    "composite_score": 0.9010063020667792,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 49.20320639327111,
    "chrf": 75.80450916056404,
    "bertscore_precision": 0.9415664672851562,
    "bertscore_recall": 0.9505005478858948,
    "bertscore_f1": 0.9460124373435974,
    "labse_similarity": 0.8841110467910767,
    "comet_score": 0.9018770456314087,
    "flesch_reading_ease": 51.63358283433135,
    "flesch_kincaid_grade": 10.008665526090677,
    "composite_score": 0.849005172103264,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 36.77660479494523,
    "chrf": 71.23643041944308,
    "bertscore_precision": 0.9397472143173218,
    "bertscore_recall": 0.9466506838798523,
    "bertscore_f1": 0.943186342716217,
    "labse_similarity": 0.8781774640083313,
    "comet_score": 0.8991930484771729,
    "flesch_reading_ease": 57.83016816774557,
    "flesch_kincaid_grade": 8.84055305375739,
    "composite_score": 0.8270209081599345,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 48.42157306860127,
    "chrf": 75.08280366431194,
    "bertscore_precision": 0.9760941863059998,
    "bertscore_recall": 0.9728628993034363,
    "bertscore_f1": 0.9744758605957031,
    "labse_similarity": 0.8692434430122375,
    "comet_score": 0.9108176231384277,
    "flesch_reading_ease": 58.1504586129754,
    "flesch_kincaid_grade": 8.673815915627994,
    "composite_score": 0.8549416311308345,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 32.48564979899249,
    "chrf": 65.81123038992615,
    "bertscore_precision": 0.9340548515319824,
    "bertscore_recall": 0.944675624370575,
    "bertscore_f1": 0.9393352270126343,
    "labse_similarity": 0.8632915616035461,
    "comet_score": 0.8917335271835327,
    "flesch_reading_ease": 51.180380021715536,
    "flesch_kincaid_grade": 9.752470916705448,
    "composite_score": 0.8085947576042645,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 63.5300177182205,
    "chrf": 85.29709387139096,
    "bertscore_precision": 0.9737788438796997,
    "bertscore_recall": 0.9784244298934937,
    "bertscore_f1": 0.9760960936546326,
    "labse_similarity": 0.913027286529541,
    "comet_score": 0.9103347063064575,
    "flesch_reading_ease": 60.836767079074775,
    "flesch_kincaid_grade": 8.590575578267888,
    "composite_score": 0.8944936205042193,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 65.7954993548311,
    "chrf": 84.73415053043492,
    "bertscore_precision": 0.9832190871238708,
    "bertscore_recall": 0.9841859936714172,
    "bertscore_f1": 0.9837023019790649,
    "labse_similarity": 0.9076439738273621,
    "comet_score": 0.915735125541687,
    "flesch_reading_ease": 53.832857142857165,
    "flesch_kincaid_grade": 9.477142857142859,
    "composite_score": 0.8984699918950971,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 45.455228181652686,
    "chrf": 74.48598003033592,
    "bertscore_precision": 0.9371067881584167,
    "bertscore_recall": 0.9496241807937622,
    "bertscore_f1": 0.9433239698410034,
    "labse_similarity": 0.8956135511398315,
    "comet_score": 0.8849165439605713,
    "flesch_reading_ease": 56.60993256262046,
    "flesch_kincaid_grade": 9.456523534269198,
    "composite_score": 0.8405332353975667,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 79.68480666882952,
    "chrf": 87.50459776739456,
    "bertscore_precision": 0.9863120317459106,
    "bertscore_recall": 0.9853676557540894,
    "bertscore_f1": 0.9858396053314209,
    "labse_similarity": 0.9169175624847412,
    "comet_score": 0.9156669974327087,
    "flesch_reading_ease": 84.31241183200972,
    "flesch_kincaid_grade": 4.0556313097321315,
    "composite_score": 0.918993846774473,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 75.19641092833875,
    "chrf": 84.80191944619921,
    "bertscore_precision": 0.9857813715934753,
    "bertscore_recall": 0.9845406413078308,
    "bertscore_f1": 0.9851606488227844,
    "labse_similarity": 0.9181070923805237,
    "comet_score": 0.9169681668281555,
    "flesch_reading_ease": 81.98182062298606,
    "flesch_kincaid_grade": 4.387239527389905,
    "composite_score": 0.9108109449276163,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 80.73791467168476,
    "chrf": 88.69818428999396,
    "bertscore_precision": 0.9855397343635559,
    "bertscore_recall": 0.9847357273101807,
    "bertscore_f1": 0.9851375818252563,
    "labse_similarity": 0.9153015613555908,
    "comet_score": 0.9172364473342896,
    "flesch_reading_ease": 84.26728947368423,
    "flesch_kincaid_grade": 4.120763157894739,
    "composite_score": 0.9216958897589432,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 55.581488525082236,
    "chrf": 76.07766252823522,
    "bertscore_precision": 0.940244197845459,
    "bertscore_recall": 0.9468110799789429,
    "bertscore_f1": 0.9435162544250488,
    "labse_similarity": 0.8957757949829102,
    "comet_score": 0.9118184447288513,
    "flesch_reading_ease": 82.04974665133273,
    "flesch_kincaid_grade": 4.3581524827492935,
    "composite_score": 0.8598626288237448,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 51.504774696009505,
    "chrf": 72.37238157333205,
    "bertscore_precision": 0.9681048393249512,
    "bertscore_recall": 0.9667288661003113,
    "bertscore_f1": 0.9674163460731506,
    "labse_similarity": 0.888703465461731,
    "comet_score": 0.9073865413665771,
    "flesch_reading_ease": 72.68685275525628,
    "flesch_kincaid_grade": 5.624862580733822,
    "composite_score": 0.8548755793119431,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 28.80194559110678,
    "chrf": 63.26729928995336,
    "bertscore_precision": 0.8990205526351929,
    "bertscore_recall": 0.9151228070259094,
    "bertscore_f1": 0.9070001840591431,
    "labse_similarity": 0.8740302324295044,
    "comet_score": 0.8832048177719116,
    "flesch_reading_ease": 78.6508214236636,
    "flesch_kincaid_grade": 4.793008794833039,
    "composite_score": 0.7914102006726585,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 70.22085229054053,
    "chrf": 83.09047546467725,
    "bertscore_precision": 0.9782081842422485,
    "bertscore_recall": 0.9763816595077515,
    "bertscore_f1": 0.9772940874099731,
    "labse_similarity": 0.8871299624443054,
    "comet_score": 0.9045391082763672,
    "flesch_reading_ease": 82.71085640590312,
    "flesch_kincaid_grade": 4.3574670236385025,
    "composite_score": 0.8916055612685011,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 60.02185464560851,
    "chrf": 76.32939402002599,
    "bertscore_precision": 0.9775964021682739,
    "bertscore_recall": 0.9744040369987488,
    "bertscore_f1": 0.9759976267814636,
    "labse_similarity": 0.8830965757369995,
    "comet_score": 0.9101046919822693,
    "flesch_reading_ease": 79.31348460904219,
    "flesch_kincaid_grade": 4.700580596399615,
    "composite_score": 0.8714607218530537,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 39.70455177711377,
    "chrf": 68.150745805419,
    "bertscore_precision": 0.9042059183120728,
    "bertscore_recall": 0.9212411642074585,
    "bertscore_f1": 0.91264408826828,
    "labse_similarity": 0.8491300940513611,
    "comet_score": 0.8803024888038635,
    "flesch_reading_ease": 76.52315351998925,
    "flesch_kincaid_grade": 5.142076322519852,
    "composite_score": 0.8056255379769643,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 68.97018119505798,
    "chrf": 82.6208347806927,
    "bertscore_precision": 0.9763044118881226,
    "bertscore_recall": 0.9756327867507935,
    "bertscore_f1": 0.9759684801101685,
    "labse_similarity": 0.9243040084838867,
    "comet_score": 0.9123570919036865,
    "flesch_reading_ease": 82.31734962406016,
    "flesch_kincaid_grade": 4.386203007518798,
    "composite_score": 0.8986420520718464,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 69.35763518288827,
    "chrf": 81.95295529252441,
    "bertscore_precision": 0.9801681041717529,
    "bertscore_recall": 0.9755420088768005,
    "bertscore_f1": 0.977849543094635,
    "labse_similarity": 0.9289343357086182,
    "comet_score": 0.9133633971214294,
    "flesch_reading_ease": 80.51862247777622,
    "flesch_kincaid_grade": 4.467112318329338,
    "composite_score": 0.8997696474721463,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 62.66418960368085,
    "chrf": 78.91393590120113,
    "bertscore_precision": 0.9359877705574036,
    "bertscore_recall": 0.9518643617630005,
    "bertscore_f1": 0.9438592791557312,
    "labse_similarity": 0.9068467617034912,
    "comet_score": 0.8900810480117798,
    "flesch_reading_ease": 81.23174089068826,
    "flesch_kincaid_grade": 4.4787854251012185,
    "composite_score": 0.8680824915458452,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 53.362788651129385,
    "chrf": 72.14069239590145,
    "bertscore_precision": 0.9616281986236572,
    "bertscore_recall": 0.9627594947814941,
    "bertscore_f1": 0.962193489074707,
    "labse_similarity": 0.8718741536140442,
    "comet_score": 0.9018726348876953,
    "flesch_reading_ease": 79.33594124377441,
    "flesch_kincaid_grade": 4.749748956790956,
    "composite_score": 0.8500748634121262,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 52.990503165039456,
    "chrf": 71.30682409450006,
    "bertscore_precision": 0.9678890705108643,
    "bertscore_recall": 0.9629871249198914,
    "bertscore_f1": 0.9654318690299988,
    "labse_similarity": 0.8751595616340637,
    "comet_score": 0.9092138409614563,
    "flesch_reading_ease": 78.67637676508345,
    "flesch_kincaid_grade": 4.697918271287978,
    "composite_score": 0.851915672582966,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 39.55592661632903,
    "chrf": 64.69865299422601,
    "bertscore_precision": 0.9129732847213745,
    "bertscore_recall": 0.9307008385658264,
    "bertscore_f1": 0.9217517971992493,
    "labse_similarity": 0.8531825542449951,
    "comet_score": 0.8942091464996338,
    "flesch_reading_ease": 77.78516430670585,
    "flesch_kincaid_grade": 4.985663905957789,
    "composite_score": 0.8073182427413502,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 54.67891887480604,
    "chrf": 77.43248903481536,
    "bertscore_precision": 0.9268214702606201,
    "bertscore_recall": 0.9342001676559448,
    "bertscore_f1": 0.9304962158203125,
    "labse_similarity": 0.8808349967002869,
    "comet_score": 0.8370835781097412,
    "flesch_reading_ease": 71.89349735114592,
    "flesch_kincaid_grade": 6.219300357019467,
    "composite_score": 0.8354144110406154,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 62.22837067880227,
    "chrf": 78.6259056943683,
    "bertscore_precision": 0.9712110757827759,
    "bertscore_recall": 0.9690045118331909,
    "bertscore_f1": 0.9701065421104431,
    "labse_similarity": 0.8766420483589172,
    "comet_score": 0.9032037258148193,
    "flesch_reading_ease": 80.03305627931216,
    "flesch_kincaid_grade": 4.737503908285564,
    "composite_score": 0.8723285329789758,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 50.26573988985967,
    "chrf": 72.98014296082968,
    "bertscore_precision": 0.9163269400596619,
    "bertscore_recall": 0.931991457939148,
    "bertscore_f1": 0.9240928292274475,
    "labse_similarity": 0.8930756449699402,
    "comet_score": 0.8940083980560303,
    "flesch_reading_ease": 77.49970624235007,
    "flesch_kincaid_grade": 5.260832313341492,
    "composite_score": 0.839081031607334,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 42.333946819273926,
    "chrf": 72.25575165396151,
    "bertscore_precision": 0.9100238084793091,
    "bertscore_recall": 0.9184777736663818,
    "bertscore_f1": 0.9142312407493591,
    "labse_similarity": 0.9029554128646851,
    "comet_score": 0.8868811726570129,
    "flesch_reading_ease": 79.22819139194142,
    "flesch_kincaid_grade": 5.06232142857143,
    "composite_score": 0.8272983222622141,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 47.32359485804042,
    "chrf": 70.3478115366725,
    "bertscore_precision": 0.9638371467590332,
    "bertscore_recall": 0.9552143812179565,
    "bertscore_f1": 0.9595063924789429,
    "labse_similarity": 0.9262621998786926,
    "comet_score": 0.9072373509407043,
    "flesch_reading_ease": 77.64896520963426,
    "flesch_kincaid_grade": 4.743157894736843,
    "composite_score": 0.8527590076176466,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 33.24817569370522,
    "chrf": 63.56113248540672,
    "bertscore_precision": 0.9108086824417114,
    "bertscore_recall": 0.9272915124893188,
    "bertscore_f1": 0.9189761877059937,
    "labse_similarity": 0.8891710042953491,
    "comet_score": 0.8824154138565063,
    "flesch_reading_ease": 76.89327935222671,
    "flesch_kincaid_grade": 5.083913630229421,
    "composite_score": 0.8027207850568098,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 71.29252901517961,
    "chrf": 84.81818216479223,
    "bertscore_precision": 0.9762900471687317,
    "bertscore_recall": 0.9745266437530518,
    "bertscore_f1": 0.975407600402832,
    "labse_similarity": 0.9372599720954895,
    "comet_score": 0.9079035520553589,
    "flesch_reading_ease": 85.79673962239754,
    "flesch_kincaid_grade": 3.9531986292512613,
    "composite_score": 0.905569964816155,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 75.046360753627,
    "chrf": 84.5586941855648,
    "bertscore_precision": 0.983081579208374,
    "bertscore_recall": 0.9818450212478638,
    "bertscore_f1": 0.9824628829956055,
    "labse_similarity": 0.9177038669586182,
    "comet_score": 0.9152126312255859,
    "flesch_reading_ease": 82.01026614079281,
    "flesch_kincaid_grade": 4.415959830306246,
    "composite_score": 0.908967198128776,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 54.843025430425904,
    "chrf": 72.89966644401534,
    "bertscore_precision": 0.9249369502067566,
    "bertscore_recall": 0.9396213293075562,
    "bertscore_f1": 0.9322213530540466,
    "labse_similarity": 0.9296438097953796,
    "comet_score": 0.8957816362380981,
    "flesch_reading_ease": 82.43945543603537,
    "flesch_kincaid_grade": 4.447622614931493,
    "composite_score": 0.8537331020312633,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 75.86525397170455,
    "chrf": 88.89143812772028,
    "bertscore_precision": 0.9780487418174744,
    "bertscore_recall": 0.978640079498291,
    "bertscore_f1": 0.9783442616462708,
    "labse_similarity": 0.8997397422790527,
    "comet_score": 0.9140591621398926,
    "flesch_reading_ease": 64.38109106715933,
    "flesch_kincaid_grade": 7.370362964572919,
    "composite_score": 0.9111684286479497,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 74.01390257368205,
    "chrf": 88.06392541225934,
    "bertscore_precision": 0.9825257658958435,
    "bertscore_recall": 0.9830945730209351,
    "bertscore_f1": 0.9828100800514221,
    "labse_similarity": 0.9081191420555115,
    "comet_score": 0.9155380725860596,
    "flesch_reading_ease": 61.65251355132017,
    "flesch_kincaid_grade": 7.733612519671272,
    "composite_score": 0.9114611612651149,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 63.62644540406684,
    "chrf": 83.22424967204313,
    "bertscore_precision": 0.95606529712677,
    "bertscore_recall": 0.965480625629425,
    "bertscore_f1": 0.9607498645782471,
    "labse_similarity": 0.9033828377723694,
    "comet_score": 0.9105192422866821,
    "flesch_reading_ease": 59.83313362238869,
    "flesch_kincaid_grade": 7.981602067183463,
    "composite_score": 0.88499415741175,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 46.5225262609531,
    "chrf": 75.78752068604845,
    "bertscore_precision": 0.9370534420013428,
    "bertscore_recall": 0.9438005685806274,
    "bertscore_f1": 0.9404149055480957,
    "labse_similarity": 0.8951278924942017,
    "comet_score": 0.9004221558570862,
    "flesch_reading_ease": 59.01175249169438,
    "flesch_kincaid_grade": 8.26371262458472,
    "composite_score": 0.8464593964175664,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 47.650349865171876,
    "chrf": 73.15257966426546,
    "bertscore_precision": 0.9584864974021912,
    "bertscore_recall": 0.9573571085929871,
    "bertscore_f1": 0.9579214453697205,
    "labse_similarity": 0.8964629769325256,
    "comet_score": 0.9013454914093018,
    "flesch_reading_ease": 48.472388685406656,
    "flesch_kincaid_grade": 9.54308812497242,
    "composite_score": 0.8493846212113167,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 38.21926751988944,
    "chrf": 70.44729798320738,
    "bertscore_precision": 0.9227676391601562,
    "bertscore_recall": 0.93037348985672,
    "bertscore_f1": 0.9265549778938293,
    "labse_similarity": 0.8810640573501587,
    "comet_score": 0.8933212757110596,
    "flesch_reading_ease": 54.81434620447564,
    "flesch_kincaid_grade": 8.675844668714351,
    "composite_score": 0.8213998382606459,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 56.93519854619441,
    "chrf": 79.5971516422952,
    "bertscore_precision": 0.943276584148407,
    "bertscore_recall": 0.9500589370727539,
    "bertscore_f1": 0.9466555714607239,
    "labse_similarity": 0.8970247507095337,
    "comet_score": 0.9046939611434937,
    "flesch_reading_ease": 59.94039329685364,
    "flesch_kincaid_grade": 8.041747606019154,
    "composite_score": 0.8659060378756346,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 58.728869265389065,
    "chrf": 77.21318697687654,
    "bertscore_precision": 0.9697214365005493,
    "bertscore_recall": 0.9707398414611816,
    "bertscore_f1": 0.9702304005622864,
    "labse_similarity": 0.9097346663475037,
    "comet_score": 0.9068890810012817,
    "flesch_reading_ease": 60.37709302325584,
    "flesch_kincaid_grade": 7.81906976744186,
    "composite_score": 0.8742869734192109,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 53.61005557221532,
    "chrf": 73.15081926743007,
    "bertscore_precision": 0.9457937479019165,
    "bertscore_recall": 0.9547463655471802,
    "bertscore_f1": 0.9502489566802979,
    "labse_similarity": 0.9064987897872925,
    "comet_score": 0.9040689468383789,
    "flesch_reading_ease": 61.64096601073345,
    "flesch_kincaid_grade": 7.665894454382826,
    "composite_score": 0.8557279661445031,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 69.66356507678238,
    "chrf": 85.80374195193706,
    "bertscore_precision": 0.9516116380691528,
    "bertscore_recall": 0.9580429792404175,
    "bertscore_f1": 0.9548165202140808,
    "labse_similarity": 0.9141069650650024,
    "comet_score": 0.910660982131958,
    "flesch_reading_ease": 63.92375176667096,
    "flesch_kincaid_grade": 7.480371750396163,
    "composite_score": 0.8953007726149022,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 69.38584606662279,
    "chrf": 86.00911060671693,
    "bertscore_precision": 0.9742178916931152,
    "bertscore_recall": 0.9731122851371765,
    "bertscore_f1": 0.9736647009849548,
    "labse_similarity": 0.9261640906333923,
    "comet_score": 0.9076396226882935,
    "flesch_reading_ease": 63.286428219245636,
    "flesch_kincaid_grade": 7.702145615909281,
    "composite_score": 0.9026416460709363,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 66.56381878355958,
    "chrf": 85.16189854762503,
    "bertscore_precision": 0.956502377986908,
    "bertscore_recall": 0.9647108912467957,
    "bertscore_f1": 0.9605891108512878,
    "labse_similarity": 0.8941189050674438,
    "comet_score": 0.9115763306617737,
    "flesch_reading_ease": 61.54333509513745,
    "flesch_kincaid_grade": 7.725731148696266,
    "composite_score": 0.8892012635393156,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 57.420356741699955,
    "chrf": 76.92761516395402,
    "bertscore_precision": 0.9674341082572937,
    "bertscore_recall": 0.9678630232810974,
    "bertscore_f1": 0.9676485657691956,
    "labse_similarity": 0.8448944687843323,
    "comet_score": 0.9074002504348755,
    "flesch_reading_ease": 61.33855813953491,
    "flesch_kincaid_grade": 7.73696124031008,
    "composite_score": 0.858935305583975,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 50.38578434408895,
    "chrf": 72.96724150061115,
    "bertscore_precision": 0.9650408029556274,
    "bertscore_recall": 0.96525639295578,
    "bertscore_f1": 0.9651486277580261,
    "labse_similarity": 0.8336367607116699,
    "comet_score": 0.9041457176208496,
    "flesch_reading_ease": 56.59750447227191,
    "flesch_kincaid_grade": 8.369355992844365,
    "composite_score": 0.8421450164699599,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 45.24468239672705,
    "chrf": 70.81974575968196,
    "bertscore_precision": 0.9389252662658691,
    "bertscore_recall": 0.949600338935852,
    "bertscore_f1": 0.9442326426506042,
    "labse_similarity": 0.8141306042671204,
    "comet_score": 0.8987439870834351,
    "flesch_reading_ease": 60.17673524150268,
    "flesch_kincaid_grade": 7.870125223613595,
    "composite_score": 0.8222562114557141,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 67.57189891188274,
    "chrf": 83.89844865956205,
    "bertscore_precision": 0.949646532535553,
    "bertscore_recall": 0.9553883075714111,
    "bertscore_f1": 0.952508807182312,
    "labse_similarity": 0.9373340010643005,
    "comet_score": 0.9050779342651367,
    "flesch_reading_ease": 62.24356376181959,
    "flesch_kincaid_grade": 7.732056393219185,
    "composite_score": 0.8929084978350638,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 64.09609351117588,
    "chrf": 81.31232672964654,
    "bertscore_precision": 0.9694748520851135,
    "bertscore_recall": 0.9681130051612854,
    "bertscore_f1": 0.9687934517860413,
    "labse_similarity": 0.8999096751213074,
    "comet_score": 0.9056179523468018,
    "flesch_reading_ease": 58.86209501557633,
    "flesch_kincaid_grade": 8.213744993324433,
    "composite_score": 0.88308904225242,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 47.3280264199605,
    "chrf": 76.242138366452,
    "bertscore_precision": 0.9038597941398621,
    "bertscore_recall": 0.9182220697402954,
    "bertscore_f1": 0.9109843373298645,
    "labse_similarity": 0.8847434520721436,
    "comet_score": 0.8417320251464844,
    "flesch_reading_ease": 55.46997093023256,
    "flesch_kincaid_grade": 8.850158268733853,
    "composite_score": 0.8223682318696476,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 45.83672404258557,
    "chrf": 75.14100577208991,
    "bertscore_precision": 0.9416506886482239,
    "bertscore_recall": 0.9427160024642944,
    "bertscore_f1": 0.9421830177307129,
    "labse_similarity": 0.9012778997421265,
    "comet_score": 0.8985052108764648,
    "flesch_reading_ease": 58.92648053724662,
    "flesch_kincaid_grade": 8.28138374165734,
    "composite_score": 0.8460850206874757,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 50.032171969763795,
    "chrf": 74.6366786715877,
    "bertscore_precision": 0.9630653262138367,
    "bertscore_recall": 0.964536190032959,
    "bertscore_f1": 0.9638001918792725,
    "labse_similarity": 0.9071073532104492,
    "comet_score": 0.8968296051025391,
    "flesch_reading_ease": 55.86910660833527,
    "flesch_kincaid_grade": 8.38429196408013,
    "composite_score": 0.8567561194586516,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 31.00523571813666,
    "chrf": 65.02102383318625,
    "bertscore_precision": 0.9314132928848267,
    "bertscore_recall": 0.9389532208442688,
    "bertscore_f1": 0.9351680278778076,
    "labse_similarity": 0.8803274035453796,
    "comet_score": 0.8878058195114136,
    "flesch_reading_ease": 54.193859083582794,
    "flesch_kincaid_grade": 8.617955330416763,
    "composite_score": 0.8071041154181876,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 67.86915418334829,
    "chrf": 86.40382421438805,
    "bertscore_precision": 0.9605533480644226,
    "bertscore_recall": 0.9654757976531982,
    "bertscore_f1": 0.9630082249641418,
    "labse_similarity": 0.9408232569694519,
    "comet_score": 0.914358377456665,
    "flesch_reading_ease": 66.1571530382596,
    "flesch_kincaid_grade": 7.255518046178214,
    "composite_score": 0.9031316037522295,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 72.24473182730664,
    "chrf": 86.18253542505839,
    "bertscore_precision": 0.9816954731941223,
    "bertscore_recall": 0.981437087059021,
    "bertscore_f1": 0.9815662503242493,
    "labse_similarity": 0.948782205581665,
    "comet_score": 0.9120165109634399,
    "flesch_reading_ease": 63.464977965879854,
    "flesch_kincaid_grade": 7.486587547449716,
    "composite_score": 0.9137489789193619,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 50.26942283505951,
    "chrf": 74.80792328424735,
    "bertscore_precision": 0.9486505389213562,
    "bertscore_recall": 0.955170750617981,
    "bertscore_f1": 0.9518994688987732,
    "labse_similarity": 0.9413416385650635,
    "comet_score": 0.9029501676559448,
    "flesch_reading_ease": 61.69657208496233,
    "flesch_kincaid_grade": 7.98744992140583,
    "composite_score": 0.8620570180580613,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 71.65157785932377,
    "chrf": 87.20123387462387,
    "bertscore_precision": 0.9322472810745239,
    "bertscore_recall": 0.9459452033042908,
    "bertscore_f1": 0.939046323299408,
    "labse_similarity": 0.9275670051574707,
    "comet_score": 0.9093466997146606,
    "flesch_reading_ease": 64.7702542340519,
    "flesch_kincaid_grade": 8.002478567200662,
    "composite_score": 0.8970174016212412,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 74.06189805566395,
    "chrf": 88.0721998053362,
    "bertscore_precision": 0.9844062328338623,
    "bertscore_recall": 0.9841294288635254,
    "bertscore_f1": 0.9842678308486938,
    "labse_similarity": 0.93010014295578,
    "comet_score": 0.9135095477104187,
    "flesch_reading_ease": 64.5495312959154,
    "flesch_kincaid_grade": 7.937485551963956,
    "composite_score": 0.915847962537037,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 65.59624401984397,
    "chrf": 84.82596337723898,
    "bertscore_precision": 0.9325311779975891,
    "bertscore_recall": 0.9497331380844116,
    "bertscore_f1": 0.9410535097122192,
    "labse_similarity": 0.8824318051338196,
    "comet_score": 0.9069701433181763,
    "flesch_reading_ease": 63.855284013605456,
    "flesch_kincaid_grade": 7.975704081632653,
    "composite_score": 0.8783801388556761,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 47.54457078855627,
    "chrf": 77.1825615749529,
    "bertscore_precision": 0.9194072484970093,
    "bertscore_recall": 0.929053544998169,
    "bertscore_f1": 0.9242051839828491,
    "labse_similarity": 0.9038870930671692,
    "comet_score": 0.8987728357315063,
    "flesch_reading_ease": 60.31665606527886,
    "flesch_kincaid_grade": 8.682209769798437,
    "composite_score": 0.8460505958921508,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 43.66305078250318,
    "chrf": 73.18116636165935,
    "bertscore_precision": 0.9497025609016418,
    "bertscore_recall": 0.9497724771499634,
    "bertscore_f1": 0.9497374892234802,
    "labse_similarity": 0.8959444761276245,
    "comet_score": 0.8965861201286316,
    "flesch_reading_ease": 52.8038148069879,
    "flesch_kincaid_grade": 9.39294801352494,
    "composite_score": 0.8416914723497192,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 42.41249630691485,
    "chrf": 71.75089709583521,
    "bertscore_precision": 0.9058953523635864,
    "bertscore_recall": 0.9199973344802856,
    "bertscore_f1": 0.9128918647766113,
    "labse_similarity": 0.8565595746040344,
    "comet_score": 0.8895747661590576,
    "flesch_reading_ease": 54.95215952773205,
    "flesch_kincaid_grade": 9.184978818545538,
    "composite_score": 0.8176120078442224,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 63.16445700803513,
    "chrf": 82.30658136269764,
    "bertscore_precision": 0.9303686618804932,
    "bertscore_recall": 0.9415237903594971,
    "bertscore_f1": 0.9359129667282104,
    "labse_similarity": 0.8843351602554321,
    "comet_score": 0.9080859422683716,
    "flesch_reading_ease": 63.329726598702536,
    "flesch_kincaid_grade": 8.083678938339283,
    "composite_score": 0.8712867366887239,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 58.947108067684354,
    "chrf": 79.65814271970959,
    "bertscore_precision": 0.9726819396018982,
    "bertscore_recall": 0.9737577438354492,
    "bertscore_f1": 0.9732195138931274,
    "labse_similarity": 0.8869194984436035,
    "comet_score": 0.9055708646774292,
    "flesch_reading_ease": 60.69460878572724,
    "flesch_kincaid_grade": 8.379390349377477,
    "composite_score": 0.8741767921732649,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 55.63651070593083,
    "chrf": 78.2232900648336,
    "bertscore_precision": 0.9314495325088501,
    "bertscore_recall": 0.9493292570114136,
    "bertscore_f1": 0.9403043985366821,
    "labse_similarity": 0.8582623600959778,
    "comet_score": 0.8982776403427124,
    "flesch_reading_ease": 61.98300894854589,
    "flesch_kincaid_grade": 8.139252157238733,
    "composite_score": 0.8512846474690595,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 59.165554765470084,
    "chrf": 83.25741934418386,
    "bertscore_precision": 0.9438575506210327,
    "bertscore_recall": 0.9452366828918457,
    "bertscore_f1": 0.9445465803146362,
    "labse_similarity": 0.8599764108657837,
    "comet_score": 0.9010801315307617,
    "flesch_reading_ease": 63.75075716740696,
    "flesch_kincaid_grade": 8.207533172440346,
    "composite_score": 0.864680972931984,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 73.85503773677904,
    "chrf": 87.7676575534532,
    "bertscore_precision": 0.9766137599945068,
    "bertscore_recall": 0.9770336151123047,
    "bertscore_f1": 0.976823627948761,
    "labse_similarity": 0.9124689102172852,
    "comet_score": 0.9129276275634766,
    "flesch_reading_ease": 64.69540225417802,
    "flesch_kincaid_grade": 7.854284233709034,
    "composite_score": 0.9092793013859133,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 59.14762307403642,
    "chrf": 83.17960176570743,
    "bertscore_precision": 0.9244507551193237,
    "bertscore_recall": 0.9405502080917358,
    "bertscore_f1": 0.9324309825897217,
    "labse_similarity": 0.8438457250595093,
    "comet_score": 0.8972820043563843,
    "flesch_reading_ease": 63.40581030670785,
    "flesch_kincaid_grade": 8.117963397648804,
    "composite_score": 0.8567359666005121,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 56.06329243240672,
    "chrf": 78.70494662571774,
    "bertscore_precision": 0.9267507195472717,
    "bertscore_recall": 0.9403425455093384,
    "bertscore_f1": 0.9334971308708191,
    "labse_similarity": 0.8871271014213562,
    "comet_score": 0.9083766937255859,
    "flesch_reading_ease": 62.259381615920574,
    "flesch_kincaid_grade": 8.322763770737904,
    "composite_score": 0.8586894453478966,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 52.05876118724609,
    "chrf": 75.69047100043593,
    "bertscore_precision": 0.9624084830284119,
    "bertscore_recall": 0.9625785946846008,
    "bertscore_f1": 0.9624935388565063,
    "labse_similarity": 0.8928952217102051,
    "comet_score": 0.9030615091323853,
    "flesch_reading_ease": 57.29084770960449,
    "flesch_kincaid_grade": 8.76136029981107,
    "composite_score": 0.8586869509699893,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 44.791525352924914,
    "chrf": 73.18872893178613,
    "bertscore_precision": 0.9158092737197876,
    "bertscore_recall": 0.931710422039032,
    "bertscore_f1": 0.92369145154953,
    "labse_similarity": 0.8420838117599487,
    "comet_score": 0.8954703211784363,
    "flesch_reading_ease": 58.95193707482994,
    "flesch_kincaid_grade": 8.659622448979594,
    "composite_score": 0.8239663968620621,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 59.559173950367814,
    "chrf": 82.89406528196524,
    "bertscore_precision": 0.9222241044044495,
    "bertscore_recall": 0.9320062398910522,
    "bertscore_f1": 0.9270893931388855,
    "labse_similarity": 0.9077938199043274,
    "comet_score": 0.8961286544799805,
    "flesch_reading_ease": 63.190647857889275,
    "flesch_kincaid_grade": 8.219238692342142,
    "composite_score": 0.8676180174158419,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 61.97491434349469,
    "chrf": 80.5026557197105,
    "bertscore_precision": 0.9521159529685974,
    "bertscore_recall": 0.9556286334991455,
    "bertscore_f1": 0.9538690447807312,
    "labse_similarity": 0.892159640789032,
    "comet_score": 0.9055068492889404,
    "flesch_reading_ease": 62.46916415662653,
    "flesch_kincaid_grade": 7.994192603748331,
    "composite_score": 0.8736982518373213,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 60.390991911746184,
    "chrf": 81.89880021361935,
    "bertscore_precision": 0.9318470358848572,
    "bertscore_recall": 0.9480025768280029,
    "bertscore_f1": 0.9398553967475891,
    "labse_similarity": 0.9076778888702393,
    "comet_score": 0.9069124460220337,
    "flesch_reading_ease": 61.85250850340137,
    "flesch_kincaid_grade": 8.255051020408164,
    "composite_score": 0.8734595005360082,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 39.59172579952095,
    "chrf": 74.77587392831151,
    "bertscore_precision": 0.9111624956130981,
    "bertscore_recall": 0.921276330947876,
    "bertscore_f1": 0.9161914587020874,
    "labse_similarity": 0.9041267037391663,
    "comet_score": 0.8905661106109619,
    "flesch_reading_ease": 62.13789010478732,
    "flesch_kincaid_grade": 8.253827626690967,
    "composite_score": 0.8300798427031882,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 44.691286471821584,
    "chrf": 74.79177703566978,
    "bertscore_precision": 0.9512200355529785,
    "bertscore_recall": 0.952489972114563,
    "bertscore_f1": 0.9518545866012573,
    "labse_similarity": 0.9156309366226196,
    "comet_score": 0.8976570963859558,
    "flesch_reading_ease": 57.7229625984252,
    "flesch_kincaid_grade": 8.588526746656672,
    "composite_score": 0.8499757894267164,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 47.194581378420445,
    "chrf": 74.18802541211173,
    "bertscore_precision": 0.9206494092941284,
    "bertscore_recall": 0.9409393668174744,
    "bertscore_f1": 0.9306838512420654,
    "labse_similarity": 0.8828853368759155,
    "comet_score": 0.8974136114120483,
    "flesch_reading_ease": 61.583846484935464,
    "flesch_kincaid_grade": 8.024855093256814,
    "composite_score": 0.8386122450974028,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 65.5329848703497,
    "chrf": 85.24224042721107,
    "bertscore_precision": 0.9271130561828613,
    "bertscore_recall": 0.933556079864502,
    "bertscore_f1": 0.9303234219551086,
    "labse_similarity": 0.9220395684242249,
    "comet_score": 0.8983638286590576,
    "flesch_reading_ease": 67.77660585984457,
    "flesch_kincaid_grade": 7.735801392928916,
    "composite_score": 0.8814922429473082,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 70.74828565220399,
    "chrf": 85.47866231612076,
    "bertscore_precision": 0.9715479612350464,
    "bertscore_recall": 0.9722106456756592,
    "bertscore_f1": 0.9718791842460632,
    "labse_similarity": 0.9176262617111206,
    "comet_score": 0.9051292538642883,
    "flesch_reading_ease": 65.56516104257669,
    "flesch_kincaid_grade": 7.870653290452648,
    "composite_score": 0.9003376002085004,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 54.558824417163216,
    "chrf": 80.03804706667333,
    "bertscore_precision": 0.9194905161857605,
    "bertscore_recall": 0.9306995868682861,
    "bertscore_f1": 0.9250611066818237,
    "labse_similarity": 0.8770979642868042,
    "comet_score": 0.8958925008773804,
    "flesch_reading_ease": 64.84993549418915,
    "flesch_kincaid_grade": 8.27271670753812,
    "composite_score": 0.8515269450984263,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 72.44979512532957,
    "chrf": 85.52392942377112,
    "bertscore_precision": 0.9481256604194641,
    "bertscore_recall": 0.9621921181678772,
    "bertscore_f1": 0.9551070928573608,
    "labse_similarity": 0.9009042978286743,
    "comet_score": 0.9192264080047607,
    "flesch_reading_ease": 76.7981077563769,
    "flesch_kincaid_grade": 5.850163109491586,
    "composite_score": 0.8972552786851193,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 73.6526069761441,
    "chrf": 83.24399024809996,
    "bertscore_precision": 0.9799248576164246,
    "bertscore_recall": 0.9795145988464355,
    "bertscore_f1": 0.9797196984291077,
    "labse_similarity": 0.9138789176940918,
    "comet_score": 0.909064769744873,
    "flesch_reading_ease": 76.5064180672269,
    "flesch_kincaid_grade": 5.861621148459388,
    "composite_score": 0.9024764778520629,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 62.86474073763662,
    "chrf": 83.62387742520745,
    "bertscore_precision": 0.9460944533348083,
    "bertscore_recall": 0.9560439586639404,
    "bertscore_f1": 0.9510431289672852,
    "labse_similarity": 0.8760004639625549,
    "comet_score": 0.9123059511184692,
    "flesch_reading_ease": 75.9401098901099,
    "flesch_kincaid_grade": 6.011428571428571,
    "composite_score": 0.8768900761377617,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 42.46658373361355,
    "chrf": 71.54828278143803,
    "bertscore_precision": 0.9173389673233032,
    "bertscore_recall": 0.9245186448097229,
    "bertscore_f1": 0.9209147691726685,
    "labse_similarity": 0.829427182674408,
    "comet_score": 0.9060713052749634,
    "flesch_reading_ease": 74.05573181818183,
    "flesch_kincaid_grade": 6.427904545454545,
    "composite_score": 0.8184667015111937,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 55.59066488654543,
    "chrf": 77.28210763165849,
    "bertscore_precision": 0.9675049185752869,
    "bertscore_recall": 0.968238115310669,
    "bertscore_f1": 0.967871367931366,
    "labse_similarity": 0.8442773818969727,
    "comet_score": 0.9141011834144592,
    "flesch_reading_ease": 72.13020805268674,
    "flesch_kincaid_grade": 6.38920520880108,
    "composite_score": 0.8592560089464523,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 45.205975796279965,
    "chrf": 72.93433637291365,
    "bertscore_precision": 0.9062440395355225,
    "bertscore_recall": 0.9266259670257568,
    "bertscore_f1": 0.9163216948509216,
    "labse_similarity": 0.849383533000946,
    "comet_score": 0.9013651609420776,
    "flesch_reading_ease": 73.52871351351354,
    "flesch_kincaid_grade": 6.312607807807808,
    "composite_score": 0.8247219856466356,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 50.5915574429881,
    "chrf": 75.54127890385082,
    "bertscore_precision": 0.9373769760131836,
    "bertscore_recall": 0.9440875053405762,
    "bertscore_f1": 0.94072026014328,
    "labse_similarity": 0.8466162085533142,
    "comet_score": 0.9060714244842529,
    "flesch_reading_ease": 75.83913626209979,
    "flesch_kincaid_grade": 6.144667824935883,
    "composite_score": 0.8419606516734743,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 67.63522181926227,
    "chrf": 82.10329401181168,
    "bertscore_precision": 0.9734224081039429,
    "bertscore_recall": 0.9736899733543396,
    "bertscore_f1": 0.9735562205314636,
    "labse_similarity": 0.8532983660697937,
    "comet_score": 0.9135544300079346,
    "flesch_reading_ease": 77.96698048780489,
    "flesch_kincaid_grade": 5.6438731707317125,
    "composite_score": 0.8819053097123611,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 49.827971483569954,
    "chrf": 72.3294770627228,
    "bertscore_precision": 0.9385948181152344,
    "bertscore_recall": 0.9496586322784424,
    "bertscore_f1": 0.9440943002700806,
    "labse_similarity": 0.8420340418815613,
    "comet_score": 0.902414083480835,
    "flesch_reading_ease": 74.62160294795027,
    "flesch_kincaid_grade": 6.042455089820361,
    "composite_score": 0.8355608064051994,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 62.96257206510666,
    "chrf": 83.52612300985471,
    "bertscore_precision": 0.9259428381919861,
    "bertscore_recall": 0.9377456903457642,
    "bertscore_f1": 0.9318069219589233,
    "labse_similarity": 0.8313999176025391,
    "comet_score": 0.9061845541000366,
    "flesch_reading_ease": 77.44666666666669,
    "flesch_kincaid_grade": 5.769444444444446,
    "composite_score": 0.8606199552130828,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 72.69628327544672,
    "chrf": 85.04619673554288,
    "bertscore_precision": 0.975411057472229,
    "bertscore_recall": 0.9752618074417114,
    "bertscore_f1": 0.9753364324569702,
    "labse_similarity": 0.8506993055343628,
    "comet_score": 0.9159749150276184,
    "flesch_reading_ease": 73.51251648641522,
    "flesch_kincaid_grade": 6.264596852193794,
    "composite_score": 0.8920000979796292,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 57.204750680997456,
    "chrf": 80.05481281634461,
    "bertscore_precision": 0.9428161382675171,
    "bertscore_recall": 0.9525545239448547,
    "bertscore_f1": 0.9476603269577026,
    "labse_similarity": 0.8448095917701721,
    "comet_score": 0.9002586007118225,
    "flesch_reading_ease": 76.67394230769231,
    "flesch_kincaid_grade": 5.932960992907805,
    "composite_score": 0.8556116365248152,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 48.45558251160134,
    "chrf": 74.93500250016808,
    "bertscore_precision": 0.929993212223053,
    "bertscore_recall": 0.9404561519622803,
    "bertscore_f1": 0.9351954460144043,
    "labse_similarity": 0.8836161494255066,
    "comet_score": 0.9124530553817749,
    "flesch_reading_ease": 73.73440533179269,
    "flesch_kincaid_grade": 6.314302575107298,
    "composite_score": 0.8462532137967198,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 66.92718490309085,
    "chrf": 82.7482971349831,
    "bertscore_precision": 0.977838397026062,
    "bertscore_recall": 0.976333737373352,
    "bertscore_f1": 0.9770854711532593,
    "labse_similarity": 0.8713843822479248,
    "comet_score": 0.9172875881195068,
    "flesch_reading_ease": 76.7847729379055,
    "flesch_kincaid_grade": 5.721626506024098,
    "composite_score": 0.8877740454310049,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 40.6962514941565,
    "chrf": 70.22272422349968,
    "bertscore_precision": 0.9216419458389282,
    "bertscore_recall": 0.9317939877510071,
    "bertscore_f1": 0.9266901612281799,
    "labse_similarity": 0.8270660638809204,
    "comet_score": 0.8991655111312866,
    "flesch_reading_ease": 74.9848381217839,
    "flesch_kincaid_grade": 6.100320540308751,
    "composite_score": 0.8142419767568657,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 50.73858955770905,
    "chrf": 76.63565173573615,
    "bertscore_precision": 0.9428921937942505,
    "bertscore_recall": 0.9465880990028381,
    "bertscore_f1": 0.9447364807128906,
    "labse_similarity": 0.8535081744194031,
    "comet_score": 0.8996171355247498,
    "flesch_reading_ease": 74.50813618856463,
    "flesch_kincaid_grade": 6.254157263751768,
    "composite_score": 0.8447189301402483,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 68.55956827770666,
    "chrf": 83.8408113438672,
    "bertscore_precision": 0.9720215201377869,
    "bertscore_recall": 0.9705911874771118,
    "bertscore_f1": 0.9713059067726135,
    "labse_similarity": 0.8979945778846741,
    "comet_score": 0.9172028303146362,
    "flesch_reading_ease": 73.28278124021742,
    "flesch_kincaid_grade": 6.394063006915395,
    "composite_score": 0.8946121804808854,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 55.867693454124456,
    "chrf": 78.59364985625847,
    "bertscore_precision": 0.9267875552177429,
    "bertscore_recall": 0.947401225566864,
    "bertscore_f1": 0.9369810223579407,
    "labse_similarity": 0.8662349581718445,
    "comet_score": 0.9076904058456421,
    "flesch_reading_ease": 73.70398666519728,
    "flesch_kincaid_grade": 6.313767908309458,
    "composite_score": 0.8550220680416736,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 42.285651172774564,
    "chrf": 73.58305756756678,
    "bertscore_precision": 0.9234557747840881,
    "bertscore_recall": 0.9288374185562134,
    "bertscore_f1": 0.9261387586593628,
    "labse_similarity": 0.8213070631027222,
    "comet_score": 0.9034726619720459,
    "flesch_reading_ease": 75.29131725417442,
    "flesch_kincaid_grade": 6.077600494743351,
    "composite_score": 0.8206314432354894,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 50.38668622827728,
    "chrf": 74.75010831487307,
    "bertscore_precision": 0.9613363146781921,
    "bertscore_recall": 0.9615480303764343,
    "bertscore_f1": 0.9614421725273132,
    "labse_similarity": 0.8763313889503479,
    "comet_score": 0.9109147191047668,
    "flesch_reading_ease": 72.10125265863171,
    "flesch_kincaid_grade": 6.312776497695854,
    "composite_score": 0.853939458025042,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 36.30243419016515,
    "chrf": 68.84379099861823,
    "bertscore_precision": 0.9182611703872681,
    "bertscore_recall": 0.9233732223510742,
    "bertscore_f1": 0.9208101034164429,
    "labse_similarity": 0.8400959968566895,
    "comet_score": 0.8916006088256836,
    "flesch_reading_ease": 75.93977080394924,
    "flesch_kincaid_grade": 5.704071056855213,
    "composite_score": 0.8067305032907841,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 63.091441897897376,
    "chrf": 81.3437927216494,
    "bertscore_precision": 0.9409353137016296,
    "bertscore_recall": 0.9476879239082336,
    "bertscore_f1": 0.9442995190620422,
    "labse_similarity": 0.9041479229927063,
    "comet_score": 0.9149737358093262,
    "flesch_reading_ease": 78.12472052721506,
    "flesch_kincaid_grade": 5.884328370352293,
    "composite_score": 0.8779700052498569,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 64.5333146482042,
    "chrf": 81.27556867160301,
    "bertscore_precision": 0.9749693870544434,
    "bertscore_recall": 0.9739053845405579,
    "bertscore_f1": 0.9744371175765991,
    "labse_similarity": 0.9232612252235413,
    "comet_score": 0.9129625558853149,
    "flesch_reading_ease": 76.03340336134454,
    "flesch_kincaid_grade": 6.1321848739495834,
    "composite_score": 0.8916706869446255,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 39.81404544323309,
    "chrf": 70.29739041845748,
    "bertscore_precision": 0.9289536476135254,
    "bertscore_recall": 0.9362999200820923,
    "bertscore_f1": 0.9326122999191284,
    "labse_similarity": 0.8995968103408813,
    "comet_score": 0.8875263929367065,
    "flesch_reading_ease": 79.10653664500973,
    "flesch_kincaid_grade": 5.9144738797919025,
    "composite_score": 0.8268447813490106,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "spanish",
    "bleu": 68.86690062458332,
    "chrf": 84.52132731344987,
    "bertscore_precision": 0.9760156869888306,
    "bertscore_recall": 0.9799543023109436,
    "bertscore_f1": 0.9779809713363647,
    "labse_similarity": 0.9159266948699951,
    "comet_score": 0.9160906076431274,
    "flesch_reading_ease": 76.74225752508363,
    "flesch_kincaid_grade": 6.322691511387166,
    "composite_score": 0.9012511738804484,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "spanish",
    "bleu": 71.72691474247446,
    "chrf": 86.12194881387803,
    "bertscore_precision": 0.9793275594711304,
    "bertscore_recall": 0.9810287952423096,
    "bertscore_f1": 0.9801774621009827,
    "labse_similarity": 0.9146960377693176,
    "comet_score": 0.9150903224945068,
    "flesch_reading_ease": 74.82973809794342,
    "flesch_kincaid_grade": 6.518470141380039,
    "composite_score": 0.9066748647710765,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "spanish",
    "bleu": 70.89217203041694,
    "chrf": 86.73573411963143,
    "bertscore_precision": 0.9840495586395264,
    "bertscore_recall": 0.9844717979431152,
    "bertscore_f1": 0.984260618686676,
    "labse_similarity": 0.8926142454147339,
    "comet_score": 0.9180123209953308,
    "flesch_reading_ease": 76.27442142454693,
    "flesch_kincaid_grade": 6.3712983222211825,
    "composite_score": 0.9042998881476463,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "chinese_simplified",
    "bleu": 43.432433253594176,
    "chrf": 73.87732815262227,
    "bertscore_precision": 0.9474586248397827,
    "bertscore_recall": 0.9490759372711182,
    "bertscore_f1": 0.9482665657997131,
    "labse_similarity": 0.8591104745864868,
    "comet_score": 0.9007533192634583,
    "flesch_reading_ease": 70.33321570529873,
    "flesch_kincaid_grade": 7.457598197239523,
    "composite_score": 0.8357388199556034,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "chinese_simplified",
    "bleu": 54.11444208131297,
    "chrf": 77.24882864138661,
    "bertscore_precision": 0.9663289189338684,
    "bertscore_recall": 0.966882050037384,
    "bertscore_f1": 0.9666054248809814,
    "labse_similarity": 0.8603031039237976,
    "comet_score": 0.9120746850967407,
    "flesch_reading_ease": 72.3502017654477,
    "flesch_kincaid_grade": 6.665027322404374,
    "composite_score": 0.8600486045666319,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "chinese_simplified",
    "bleu": 52.77703904922868,
    "chrf": 75.84758660860068,
    "bertscore_precision": 0.9579575061798096,
    "bertscore_recall": 0.9652130603790283,
    "bertscore_f1": 0.9615715742111206,
    "labse_similarity": 0.8467957973480225,
    "comet_score": 0.9118624925613403,
    "flesch_reading_ease": 72.33421882465362,
    "flesch_kincaid_grade": 6.68636645962733,
    "composite_score": 0.8523446738354054,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "vietnamese",
    "bleu": 55.38873834601452,
    "chrf": 77.09537904085715,
    "bertscore_precision": 0.9619362354278564,
    "bertscore_recall": 0.9674029350280762,
    "bertscore_f1": 0.9646618366241455,
    "labse_similarity": 0.8603870868682861,
    "comet_score": 0.9149713516235352,
    "flesch_reading_ease": 73.33017729482415,
    "flesch_kincaid_grade": 6.703058948486461,
    "composite_score": 0.8612506131740849,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "vietnamese",
    "bleu": 55.333581631197916,
    "chrf": 76.47709227928891,
    "bertscore_precision": 0.9746719598770142,
    "bertscore_recall": 0.974957287311554,
    "bertscore_f1": 0.9748145937919617,
    "labse_similarity": 0.8656436800956726,
    "comet_score": 0.9130048751831055,
    "flesch_reading_ease": 73.47410276164516,
    "flesch_kincaid_grade": 6.554675324675326,
    "composite_score": 0.8638735530026307,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "vietnamese",
    "bleu": 52.6869124256931,
    "chrf": 74.50290104163432,
    "bertscore_precision": 0.9638981819152832,
    "bertscore_recall": 0.9679527282714844,
    "bertscore_f1": 0.9659212231636047,
    "labse_similarity": 0.8317281007766724,
    "comet_score": 0.9065463542938232,
    "flesch_reading_ease": 73.198323604663,
    "flesch_kincaid_grade": 6.514120014232947,
    "composite_score": 0.8471998396660163,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "tagalog",
    "bleu": 62.796527875347046,
    "chrf": 82.44024302020213,
    "bertscore_precision": 0.963319718837738,
    "bertscore_recall": 0.9661970138549805,
    "bertscore_f1": 0.964756190776825,
    "labse_similarity": 0.85066157579422,
    "comet_score": 0.9112672805786133,
    "flesch_reading_ease": 74.23056361139558,
    "flesch_kincaid_grade": 6.68877905533315,
    "composite_score": 0.8738328849421949,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "tagalog",
    "bleu": 71.88691799886125,
    "chrf": 86.45408975651682,
    "bertscore_precision": 0.9815487861633301,
    "bertscore_recall": 0.9824883937835693,
    "bertscore_f1": 0.9820183515548706,
    "labse_similarity": 0.8732515573501587,
    "comet_score": 0.9157525300979614,
    "flesch_reading_ease": 75.92407827854964,
    "flesch_kincaid_grade": 6.3876714915040935,
    "composite_score": 0.8997620020946198,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "tagalog",
    "bleu": 58.43488587356373,
    "chrf": 80.77081541385441,
    "bertscore_precision": 0.9570961594581604,
    "bertscore_recall": 0.9625194072723389,
    "bertscore_f1": 0.9598001837730408,
    "labse_similarity": 0.8485038876533508,
    "comet_score": 0.884088397026062,
    "flesch_reading_ease": 75.6149018182943,
    "flesch_kincaid_grade": 6.509193209227533,
    "composite_score": 0.8582540409134432,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "russian",
    "bleu": 44.210068589163846,
    "chrf": 71.79588366786219,
    "bertscore_precision": 0.9486321210861206,
    "bertscore_recall": 0.9541511535644531,
    "bertscore_f1": 0.951383650302887,
    "labse_similarity": 0.8486946821212769,
    "comet_score": 0.8993890285491943,
    "flesch_reading_ease": 71.60575795172569,
    "flesch_kincaid_grade": 6.995450356095521,
    "composite_score": 0.8319051827433772,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "russian",
    "bleu": 55.99040392653102,
    "chrf": 77.43161303501122,
    "bertscore_precision": 0.9715960621833801,
    "bertscore_recall": 0.9725365042686462,
    "bertscore_f1": 0.9720660448074341,
    "labse_similarity": 0.8425909280776978,
    "comet_score": 0.9141649007797241,
    "flesch_reading_ease": 73.02723677240893,
    "flesch_kincaid_grade": 6.641573942507378,
    "composite_score": 0.8608170477317486,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "russian",
    "bleu": 44.92861066552111,
    "chrf": 70.96085763405623,
    "bertscore_precision": 0.9511867761611938,
    "bertscore_recall": 0.9590458869934082,
    "bertscore_f1": 0.9551001191139221,
    "labse_similarity": 0.836867094039917,
    "comet_score": 0.9063090085983276,
    "flesch_reading_ease": 73.1794389568524,
    "flesch_kincaid_grade": 6.603163746073729,
    "composite_score": 0.8318506038083474,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "arabic",
    "bleu": 56.365793772227775,
    "chrf": 78.05115856023558,
    "bertscore_precision": 0.9556174278259277,
    "bertscore_recall": 0.9597920179367065,
    "bertscore_f1": 0.9577001929283142,
    "labse_similarity": 0.8749521970748901,
    "comet_score": 0.9087951183319092,
    "flesch_reading_ease": 76.17370200955159,
    "flesch_kincaid_grade": 6.42045059852385,
    "composite_score": 0.8629418084890306,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "arabic",
    "bleu": 68.78833218979618,
    "chrf": 83.96680504131827,
    "bertscore_precision": 0.9793671369552612,
    "bertscore_recall": 0.9819985032081604,
    "bertscore_f1": 0.9806810021400452,
    "labse_similarity": 0.8889718055725098,
    "comet_score": 0.9130368232727051,
    "flesch_reading_ease": 74.09939409905165,
    "flesch_kincaid_grade": 6.51113937812568,
    "composite_score": 0.8949964073264653,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "arabic",
    "bleu": 62.18750866067348,
    "chrf": 81.81215486163894,
    "bertscore_precision": 0.961929440498352,
    "bertscore_recall": 0.967093825340271,
    "bertscore_f1": 0.9645047187805176,
    "labse_similarity": 0.8971211314201355,
    "comet_score": 0.9018968343734741,
    "flesch_reading_ease": 73.38516746578532,
    "flesch_kincaid_grade": 6.806694829779971,
    "composite_score": 0.8791555914646827,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "korean",
    "bleu": 42.29368153496422,
    "chrf": 71.66287068367018,
    "bertscore_precision": 0.9421320557594299,
    "bertscore_recall": 0.9458494782447815,
    "bertscore_f1": 0.9439871311187744,
    "labse_similarity": 0.8500232100486755,
    "comet_score": 0.9050601124763489,
    "flesch_reading_ease": 72.66177432909409,
    "flesch_kincaid_grade": 6.8727270835500995,
    "composite_score": 0.8292537970249242,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "korean",
    "bleu": 56.22583198040011,
    "chrf": 78.08417366042328,
    "bertscore_precision": 0.9702959060668945,
    "bertscore_recall": 0.9707492589950562,
    "bertscore_f1": 0.9705225229263306,
    "labse_similarity": 0.8601003885269165,
    "comet_score": 0.9117358922958374,
    "flesch_reading_ease": 73.24935501553081,
    "flesch_kincaid_grade": 6.4904739282886545,
    "composite_score": 0.8644629001282769,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "korean",
    "bleu": 42.71587177483688,
    "chrf": 70.70378427976837,
    "bertscore_precision": 0.9546487927436829,
    "bertscore_recall": 0.9576621055603027,
    "bertscore_f1": 0.956153154373169,
    "labse_similarity": 0.8632193803787231,
    "comet_score": 0.901624321937561,
    "flesch_reading_ease": 70.27456604446559,
    "flesch_kincaid_grade": 6.990026495915217,
    "composite_score": 0.8336674510665749,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gpt-5.1",
    "target_language": "haitian_creole",
    "bleu": 61.812528264290385,
    "chrf": 82.94098580257292,
    "bertscore_precision": 0.9576194882392883,
    "bertscore_recall": 0.9601348638534546,
    "bertscore_f1": 0.9588754773139954,
    "labse_similarity": 0.8918925523757935,
    "comet_score": 0.9009363651275635,
    "flesch_reading_ease": 78.84571435966457,
    "flesch_kincaid_grade": 6.318679100173046,
    "composite_score": 0.877499251919398,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "claude-opus-4.5",
    "target_language": "haitian_creole",
    "bleu": 75.03851143090499,
    "chrf": 87.756988726059,
    "bertscore_precision": 0.9780701398849487,
    "bertscore_recall": 0.9794666171073914,
    "bertscore_f1": 0.9787679314613342,
    "labse_similarity": 0.88643479347229,
    "comet_score": 0.9138638973236084,
    "flesch_reading_ease": 77.39360039673795,
    "flesch_kincaid_grade": 6.275521899304135,
    "composite_score": 0.906057306983754,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "gemini-3-pro",
    "target_language": "haitian_creole",
    "bleu": 50.90913022584499,
    "chrf": 79.05860380162741,
    "bertscore_precision": 0.9416964650154114,
    "bertscore_recall": 0.9443202018737793,
    "bertscore_f1": 0.9430065155029297,
    "labse_similarity": 0.8644094467163086,
    "comet_score": 0.8852224349975586,
    "flesch_reading_ease": 78.42127951256666,
    "flesch_kincaid_grade": 6.457048561999059,
    "composite_score": 0.8465864886718164,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 60.625024613118576,
    "chrf": 81.33395579037507,
    "bertscore_precision": 0.9621301889419556,
    "bertscore_recall": 0.9633145928382874,
    "bertscore_f1": 0.9627220034599304,
    "labse_similarity": 0.914975643157959,
    "comet_score": 0.9000536203384399,
    "flesch_reading_ease": 71.73410288531805,
    "flesch_kincaid_grade": 6.830687802645212,
    "composite_score": 0.8794510930528622,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 37.10439069697244,
    "chrf": 67.62091746601048,
    "bertscore_precision": 0.9345129728317261,
    "bertscore_recall": 0.9404542446136475,
    "bertscore_f1": 0.9374741911888123,
    "labse_similarity": 0.9023363590240479,
    "comet_score": 0.8842134475708008,
    "flesch_reading_ease": 61.90286992595901,
    "flesch_kincaid_grade": 7.713105257283178,
    "composite_score": 0.8212986579501417,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 51.622213701184265,
    "chrf": 74.14110134901468,
    "bertscore_precision": 0.9615760445594788,
    "bertscore_recall": 0.9622976183891296,
    "bertscore_f1": 0.9619367122650146,
    "labse_similarity": 0.8985202312469482,
    "comet_score": 0.8971000909805298,
    "flesch_reading_ease": 66.00242321387853,
    "flesch_kincaid_grade": 7.328288691259278,
    "composite_score": 0.8553939483987327,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 62.78287618130438,
    "chrf": 80.69373895821407,
    "bertscore_precision": 0.9709177613258362,
    "bertscore_recall": 0.9726865291595459,
    "bertscore_f1": 0.9718014001846313,
    "labse_similarity": 0.8781487941741943,
    "comet_score": 0.8887686729431152,
    "flesch_reading_ease": 73.26814019263111,
    "flesch_kincaid_grade": 6.421717882077157,
    "composite_score": 0.8731858317446326,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 48.384539479044484,
    "chrf": 72.37043930548687,
    "bertscore_precision": 0.9554435014724731,
    "bertscore_recall": 0.9588708877563477,
    "bertscore_f1": 0.9571540951728821,
    "labse_similarity": 0.8534117937088013,
    "comet_score": 0.8961226940155029,
    "flesch_reading_ease": 70.41856270382964,
    "flesch_kincaid_grade": 6.757737523681005,
    "composite_score": 0.8387994592347755,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 61.92327774457406,
    "chrf": 81.13130794764089,
    "bertscore_precision": 0.9710641503334045,
    "bertscore_recall": 0.9708605408668518,
    "bertscore_f1": 0.9709623456001282,
    "labse_similarity": 0.9423531293869019,
    "comet_score": 0.9085254669189453,
    "flesch_reading_ease": 70.923256320837,
    "flesch_kincaid_grade": 6.925085730892182,
    "composite_score": 0.8905109359531905,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 0.32765227362001503,
    "chrf": 16.55539437397735,
    "bertscore_precision": 0.9569205045700073,
    "bertscore_recall": 0.8953894376754761,
    "bertscore_f1": 0.9251329898834229,
    "labse_similarity": 0.882301926612854,
    "comet_score": 0.8195974826812744,
    "flesch_reading_ease": 67.94859538207807,
    "flesch_kincaid_grade": 6.9091313908741085,
    "composite_score": 0.6840603967925023,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "CARD_001",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 46.59406090370201,
    "chrf": 72.50560183042857,
    "bertscore_precision": 0.9459378719329834,
    "bertscore_recall": 0.9481523036956787,
    "bertscore_f1": 0.947043776512146,
    "labse_similarity": 0.9057976007461548,
    "comet_score": 0.8632906675338745,
    "flesch_reading_ease": 73.14979663394111,
    "flesch_kincaid_grade": 6.742748948106591,
    "composite_score": 0.8364477836356883,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 46.80909184437228,
    "chrf": 75.33039640874681,
    "bertscore_precision": 0.9419718980789185,
    "bertscore_recall": 0.9438478350639343,
    "bertscore_f1": 0.9429089426994324,
    "labse_similarity": 0.9313064217567444,
    "comet_score": 0.8874683380126953,
    "flesch_reading_ease": 61.10145414564741,
    "flesch_kincaid_grade": 9.479113698098566,
    "composite_score": 0.8508057381218449,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 42.187373870924176,
    "chrf": 71.59766925485872,
    "bertscore_precision": 0.9434444904327393,
    "bertscore_recall": 0.945460319519043,
    "bertscore_f1": 0.9444513320922852,
    "labse_similarity": 0.8416917324066162,
    "comet_score": 0.906347393989563,
    "flesch_reading_ease": 60.826853625171026,
    "flesch_kincaid_grade": 9.194908040735676,
    "composite_score": 0.8278444723596118,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 50.73744373045124,
    "chrf": 75.93628211467053,
    "bertscore_precision": 0.9598875045776367,
    "bertscore_recall": 0.9593324661254883,
    "bertscore_f1": 0.959609866142273,
    "labse_similarity": 0.8934452533721924,
    "comet_score": 0.9063377380371094,
    "flesch_reading_ease": 61.798131313131336,
    "flesch_kincaid_grade": 8.890606060606064,
    "composite_score": 0.8577983119288547,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 57.754148401318254,
    "chrf": 81.02995234389357,
    "bertscore_precision": 0.9378999471664429,
    "bertscore_recall": 0.9400022029876709,
    "bertscore_f1": 0.9389499425888062,
    "labse_similarity": 0.8997010588645935,
    "comet_score": 0.8982925415039062,
    "flesch_reading_ease": 64.93075816993465,
    "flesch_kincaid_grade": 8.613765540258658,
    "composite_score": 0.8654974068426957,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 33.72181885088228,
    "chrf": 65.79326725392913,
    "bertscore_precision": 0.9287598133087158,
    "bertscore_recall": 0.9361976981163025,
    "bertscore_f1": 0.9324638843536377,
    "labse_similarity": 0.8697019219398499,
    "comet_score": 0.8737912178039551,
    "flesch_reading_ease": 54.31072222222224,
    "flesch_kincaid_grade": 9.8355780141844,
    "composite_score": 0.8045390738768261,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 50.20176837783331,
    "chrf": 77.69168443622878,
    "bertscore_precision": 0.956024169921875,
    "bertscore_recall": 0.95719313621521,
    "bertscore_f1": 0.9566082954406738,
    "labse_similarity": 0.935322642326355,
    "comet_score": 0.9112323522567749,
    "flesch_reading_ease": 61.5545620280475,
    "flesch_kincaid_grade": 9.222692556634303,
    "composite_score": 0.8685944001938433,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 32.86333072336547,
    "chrf": 66.14942419370148,
    "bertscore_precision": 0.9429357051849365,
    "bertscore_recall": 0.9442736506462097,
    "bertscore_f1": 0.9436041712760925,
    "labse_similarity": 0.853954017162323,
    "comet_score": 0.8902801275253296,
    "flesch_reading_ease": 54.08238554216871,
    "flesch_kincaid_grade": 9.839823293172692,
    "composite_score": 0.8085295537105424,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_002",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 37.86823793007075,
    "chrf": 68.78657127499926,
    "bertscore_precision": 0.9328691363334656,
    "bertscore_recall": 0.9362871646881104,
    "bertscore_f1": 0.9345750212669373,
    "labse_similarity": 0.9476617574691772,
    "comet_score": 0.8073058128356934,
    "flesch_reading_ease": 71.00019309600866,
    "flesch_kincaid_grade": 7.905216828478963,
    "composite_score": 0.8127794059254096,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 55.01617131592161,
    "chrf": 78.7108519420535,
    "bertscore_precision": 0.9635739326477051,
    "bertscore_recall": 0.9664257168769836,
    "bertscore_f1": 0.9649977087974548,
    "labse_similarity": 0.939568281173706,
    "comet_score": 0.8944331407546997,
    "flesch_reading_ease": 63.35590876263842,
    "flesch_kincaid_grade": 8.449386133846897,
    "composite_score": 0.8741037032916544,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 46.27891672070869,
    "chrf": 70.85293985450954,
    "bertscore_precision": 0.9609892964363098,
    "bertscore_recall": 0.9606521129608154,
    "bertscore_f1": 0.960820734500885,
    "labse_similarity": 0.8882702589035034,
    "comet_score": 0.8900451064109802,
    "flesch_reading_ease": 55.89899091297082,
    "flesch_kincaid_grade": 9.096799978660595,
    "composite_score": 0.8409698752361843,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 55.8386760510631,
    "chrf": 76.49126723371386,
    "bertscore_precision": 0.9552698135375977,
    "bertscore_recall": 0.9583519101142883,
    "bertscore_f1": 0.9568084478378296,
    "labse_similarity": 0.8566653728485107,
    "comet_score": 0.8939729928970337,
    "flesch_reading_ease": 60.828150981044246,
    "flesch_kincaid_grade": 8.661715996009313,
    "composite_score": 0.8524444340469433,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 66.91266165904919,
    "chrf": 84.76270802486266,
    "bertscore_precision": 0.9533544182777405,
    "bertscore_recall": 0.9533228278160095,
    "bertscore_f1": 0.953338623046875,
    "labse_similarity": 0.8058382272720337,
    "comet_score": 0.9047763347625732,
    "flesch_reading_ease": 65.42371552359295,
    "flesch_kincaid_grade": 8.168982445462412,
    "composite_score": 0.8674200397554557,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 39.418742177576796,
    "chrf": 67.09582017202726,
    "bertscore_precision": 0.9412415623664856,
    "bertscore_recall": 0.9454513788223267,
    "bertscore_f1": 0.9433417320251465,
    "labse_similarity": 0.8745678663253784,
    "comet_score": 0.8723541498184204,
    "flesch_reading_ease": 58.270343691481514,
    "flesch_kincaid_grade": 8.790085326643819,
    "composite_score": 0.8160671027628423,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 56.983276870631215,
    "chrf": 80.09740355577838,
    "bertscore_precision": 0.9616862535476685,
    "bertscore_recall": 0.9626960754394531,
    "bertscore_f1": 0.9621909260749817,
    "labse_similarity": 0.928057074546814,
    "comet_score": 0.8938473463058472,
    "flesch_reading_ease": 64.79388986530627,
    "flesch_kincaid_grade": 8.377037515164712,
    "composite_score": 0.8748599115126179,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 40.02984438993833,
    "chrf": 69.90649800000405,
    "bertscore_precision": 0.9333778023719788,
    "bertscore_recall": 0.9390530586242676,
    "bertscore_f1": 0.9362068772315979,
    "labse_similarity": 0.876602292060852,
    "comet_score": 0.8857760429382324,
    "flesch_reading_ease": 57.80276040926532,
    "flesch_kincaid_grade": 8.835269290891006,
    "composite_score": 0.8225161237061522,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_003",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 51.883779155252505,
    "chrf": 77.08739272610924,
    "bertscore_precision": 0.9401479363441467,
    "bertscore_recall": 0.9413157105445862,
    "bertscore_f1": 0.9407314658164978,
    "labse_similarity": 0.9264112710952759,
    "comet_score": 0.8582248687744141,
    "flesch_reading_ease": 69.16439933259178,
    "flesch_kincaid_grade": 7.795487578791249,
    "composite_score": 0.8495727794020245,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 70.17516135230629,
    "chrf": 86.141891473869,
    "bertscore_precision": 0.9743931293487549,
    "bertscore_recall": 0.9768224954605103,
    "bertscore_f1": 0.9756062626838684,
    "labse_similarity": 0.9274342060089111,
    "comet_score": 0.8974047899246216,
    "flesch_reading_ease": 81.53078947368422,
    "flesch_kincaid_grade": 4.584636591478699,
    "composite_score": 0.9019079160512079,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 48.070873587895875,
    "chrf": 71.988746712705,
    "bertscore_precision": 0.9445786476135254,
    "bertscore_recall": 0.9468539357185364,
    "bertscore_f1": 0.9457149505615234,
    "labse_similarity": 0.8899306058883667,
    "comet_score": 0.8991743326187134,
    "flesch_reading_ease": 72.89394389438947,
    "flesch_kincaid_grade": 5.481725601131544,
    "composite_score": 0.842548183157762,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 63.82564486699485,
    "chrf": 79.8362594380487,
    "bertscore_precision": 0.9693894982337952,
    "bertscore_recall": 0.9711111783981323,
    "bertscore_f1": 0.9702495336532593,
    "labse_similarity": 0.8940060138702393,
    "comet_score": 0.9060611724853516,
    "flesch_reading_ease": 77.17612416107384,
    "flesch_kincaid_grade": 5.138790348354107,
    "composite_score": 0.8799713900154315,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 65.14518809395173,
    "chrf": 82.7179099188143,
    "bertscore_precision": 0.949944257736206,
    "bertscore_recall": 0.9484596252441406,
    "bertscore_f1": 0.9492013454437256,
    "labse_similarity": 0.891499400138855,
    "comet_score": 0.8860684037208557,
    "flesch_reading_ease": 81.79189265536725,
    "flesch_kincaid_grade": 4.642857142857142,
    "composite_score": 0.8737994375632758,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 48.11770462775436,
    "chrf": 71.6531330730392,
    "bertscore_precision": 0.9521203637123108,
    "bertscore_recall": 0.9528015851974487,
    "bertscore_f1": 0.9524608254432678,
    "labse_similarity": 0.9110526442527771,
    "comet_score": 0.8900495767593384,
    "flesch_reading_ease": 74.5762931034483,
    "flesch_kincaid_grade": 5.430435139573074,
    "composite_score": 0.8460585749106836,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 58.09172285982083,
    "chrf": 78.17360352951899,
    "bertscore_precision": 0.9632667303085327,
    "bertscore_recall": 0.9647535085678101,
    "bertscore_f1": 0.9640095829963684,
    "labse_similarity": 0.9217322468757629,
    "comet_score": 0.8946255445480347,
    "flesch_reading_ease": 76.17756622516559,
    "flesch_kincaid_grade": 5.313558814254179,
    "composite_score": 0.8725578385651711,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 42.20104785492633,
    "chrf": 69.77581858700718,
    "bertscore_precision": 0.9452794790267944,
    "bertscore_recall": 0.9484479427337646,
    "bertscore_f1": 0.9468610882759094,
    "labse_similarity": 0.8993825912475586,
    "comet_score": 0.8872389793395996,
    "flesch_reading_ease": 76.42325203252035,
    "flesch_kincaid_grade": 5.024947735191638,
    "composite_score": 0.8326093653026213,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "CARD_004",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 61.64506014992169,
    "chrf": 79.15342545986654,
    "bertscore_precision": 0.9636139869689941,
    "bertscore_recall": 0.9648380875587463,
    "bertscore_f1": 0.964225709438324,
    "labse_similarity": 0.9449140429496765,
    "comet_score": 0.8856725692749023,
    "flesch_reading_ease": 84.05241337491339,
    "flesch_kincaid_grade": 4.3807944757944774,
    "composite_score": 0.8800438620798795,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 81.320736401653,
    "chrf": 90.45303562378085,
    "bertscore_precision": 0.9841567277908325,
    "bertscore_recall": 0.9850532412528992,
    "bertscore_f1": 0.9846048355102539,
    "labse_similarity": 0.9421983957290649,
    "comet_score": 0.9127097129821777,
    "flesch_reading_ease": 76.66611111111114,
    "flesch_kincaid_grade": 5.436666666666667,
    "composite_score": 0.9289988478817577,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 53.33528019123257,
    "chrf": 76.28124304071804,
    "bertscore_precision": 0.9641894698143005,
    "bertscore_recall": 0.965279221534729,
    "bertscore_f1": 0.9647340774536133,
    "labse_similarity": 0.8739977478981018,
    "comet_score": 0.9089192152023315,
    "flesch_reading_ease": 69.45119704324804,
    "flesch_kincaid_grade": 6.4800154457193315,
    "composite_score": 0.8592067213685969,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 51.294633942465545,
    "chrf": 72.92186155815995,
    "bertscore_precision": 0.957760751247406,
    "bertscore_recall": 0.9590373635292053,
    "bertscore_f1": 0.9583985805511475,
    "labse_similarity": 0.8758751153945923,
    "comet_score": 0.9032909870147705,
    "flesch_reading_ease": 73.66300204498981,
    "flesch_kincaid_grade": 5.684400817995911,
    "composite_score": 0.8491947702776608,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 68.94809091079722,
    "chrf": 81.39031678738569,
    "bertscore_precision": 0.9641750454902649,
    "bertscore_recall": 0.9644759893417358,
    "bertscore_f1": 0.9643254280090332,
    "labse_similarity": 0.898226261138916,
    "comet_score": 0.9007437825202942,
    "flesch_reading_ease": 77.63968055555557,
    "flesch_kincaid_grade": 5.256708333333336,
    "composite_score": 0.8851623923524424,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 43.82652257704892,
    "chrf": 68.77646512406075,
    "bertscore_precision": 0.9498752951622009,
    "bertscore_recall": 0.9511690735816956,
    "bertscore_f1": 0.9505217671394348,
    "labse_similarity": 0.8842905163764954,
    "comet_score": 0.8731185793876648,
    "flesch_reading_ease": 71.02602222222225,
    "flesch_kincaid_grade": 6.112933333333334,
    "composite_score": 0.8272854985271857,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 42.82939930207347,
    "chrf": 72.07696069048902,
    "bertscore_precision": 0.931755006313324,
    "bertscore_recall": 0.9324801564216614,
    "bertscore_f1": 0.9321174621582031,
    "labse_similarity": 0.9101167321205139,
    "comet_score": 0.832817792892456,
    "flesch_reading_ease": 69.01566574839303,
    "flesch_kincaid_grade": 6.973002754820939,
    "composite_score": 0.8208078736324849,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 35.53781178732938,
    "chrf": 67.89863374284279,
    "bertscore_precision": 0.9410140514373779,
    "bertscore_recall": 0.9447678923606873,
    "bertscore_f1": 0.9428872466087341,
    "labse_similarity": 0.8853276968002319,
    "comet_score": 0.8861992359161377,
    "flesch_reading_ease": 64.83555783121918,
    "flesch_kincaid_grade": 6.664118657505288,
    "composite_score": 0.8188672847232946,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_001",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 60.63370067856597,
    "chrf": 81.71880830519966,
    "bertscore_precision": 0.9597820043563843,
    "bertscore_recall": 0.9579596519470215,
    "bertscore_f1": 0.958869993686676,
    "labse_similarity": 0.9401978254318237,
    "comet_score": 0.8896690607070923,
    "flesch_reading_ease": 78.17785077636621,
    "flesch_kincaid_grade": 5.396948578342407,
    "composite_score": 0.8813297415055061,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 62.2644581873769,
    "chrf": 78.57566207641098,
    "bertscore_precision": 0.9401110410690308,
    "bertscore_recall": 0.9444916844367981,
    "bertscore_f1": 0.9422962069511414,
    "labse_similarity": 0.9312210083007812,
    "comet_score": 0.8791426420211792,
    "flesch_reading_ease": 52.87738636363639,
    "flesch_kincaid_grade": 10.220189393939396,
    "composite_score": 0.8688466755527869,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 45.54627791084145,
    "chrf": 70.79142772299085,
    "bertscore_precision": 0.9335864782333374,
    "bertscore_recall": 0.9382078051567078,
    "bertscore_f1": 0.9358914494514465,
    "labse_similarity": 0.9071788787841797,
    "comet_score": 0.8767387866973877,
    "flesch_reading_ease": 47.82919372050071,
    "flesch_kincaid_grade": 10.590062384568032,
    "composite_score": 0.8331213267619445,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 59.77734974270129,
    "chrf": 79.3460385198333,
    "bertscore_precision": 0.957664966583252,
    "bertscore_recall": 0.9608117341995239,
    "bertscore_f1": 0.9592357873916626,
    "labse_similarity": 0.9193748235702515,
    "comet_score": 0.9141088128089905,
    "flesch_reading_ease": 61.7214132231405,
    "flesch_kincaid_grade": 9.022760330578514,
    "composite_score": 0.878969311656248,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 62.00596896039947,
    "chrf": 82.29467604292901,
    "bertscore_precision": 0.9495230317115784,
    "bertscore_recall": 0.9520158767700195,
    "bertscore_f1": 0.9507678747177124,
    "labse_similarity": 0.873997151851654,
    "comet_score": 0.8881266117095947,
    "flesch_reading_ease": 59.887179666487384,
    "flesch_kincaid_grade": 9.486375112067424,
    "composite_score": 0.8675094287378361,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 43.131605764690576,
    "chrf": 70.8237656760036,
    "bertscore_precision": 0.9323527216911316,
    "bertscore_recall": 0.9376901388168335,
    "bertscore_f1": 0.9350138902664185,
    "labse_similarity": 0.8931174278259277,
    "comet_score": 0.8928454518318176,
    "flesch_reading_ease": 52.79199367431775,
    "flesch_kincaid_grade": 10.439876016627508,
    "composite_score": 0.8317062698817614,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 60.85197666781822,
    "chrf": 78.2086631488428,
    "bertscore_precision": 0.9544941186904907,
    "bertscore_recall": 0.9557908773422241,
    "bertscore_f1": 0.955142080783844,
    "labse_similarity": 0.9351409077644348,
    "comet_score": 0.8827449679374695,
    "flesch_reading_ease": 50.071959491285924,
    "flesch_kincaid_grade": 10.634074422986345,
    "composite_score": 0.8724220191634899,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 43.13423175528007,
    "chrf": 68.87931950974398,
    "bertscore_precision": 0.9298717379570007,
    "bertscore_recall": 0.9317880868911743,
    "bertscore_f1": 0.9308289289474487,
    "labse_similarity": 0.9102868437767029,
    "comet_score": 0.8275161981582642,
    "flesch_reading_ease": 64.205089986156,
    "flesch_kincaid_grade": 8.7531241347485,
    "composite_score": 0.8146383079990372,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 45.99336870818639,
    "chrf": 73.5543082488922,
    "bertscore_precision": 0.960716724395752,
    "bertscore_recall": 0.9654042720794678,
    "bertscore_f1": 0.9630548357963562,
    "labse_similarity": 0.9442802667617798,
    "comet_score": 0.8943383693695068,
    "flesch_reading_ease": 51.75661288107665,
    "flesch_kincaid_grade": 9.778029387530896,
    "composite_score": 0.8576819275151641,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 43.14994835612038,
    "chrf": 73.65347238256635,
    "bertscore_precision": 0.9629112482070923,
    "bertscore_recall": 0.964390218257904,
    "bertscore_f1": 0.9636501669883728,
    "labse_similarity": 0.8908179402351379,
    "comet_score": 0.9084800481796265,
    "flesch_reading_ease": 43.51276255707762,
    "flesch_kincaid_grade": 10.644500978473584,
    "composite_score": 0.848008807118416,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 35.61562862150124,
    "chrf": 68.54061850493004,
    "bertscore_precision": 0.9466612339019775,
    "bertscore_recall": 0.9511330127716064,
    "bertscore_f1": 0.9488918781280518,
    "labse_similarity": 0.8871851563453674,
    "comet_score": 0.8527119159698486,
    "flesch_reading_ease": 45.9291891891892,
    "flesch_kincaid_grade": 10.792483912483913,
    "composite_score": 0.8137091300788476,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 49.44295872606151,
    "chrf": 71.10428776942531,
    "bertscore_precision": 0.9654823541641235,
    "bertscore_recall": 0.9648128747940063,
    "bertscore_f1": 0.9651474952697754,
    "labse_similarity": 0.8704593181610107,
    "comet_score": 0.8999039530754089,
    "flesch_reading_ease": 51.26311320754718,
    "flesch_kincaid_grade": 9.871060197663972,
    "composite_score": 0.8447114908621864,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 44.822184799587404,
    "chrf": 74.54773971038364,
    "bertscore_precision": 0.9563075304031372,
    "bertscore_recall": 0.9620757699012756,
    "bertscore_f1": 0.9591829776763916,
    "labse_similarity": 0.8891218304634094,
    "comet_score": 0.8943093419075012,
    "flesch_reading_ease": 52.91423020527861,
    "flesch_kincaid_grade": 9.729486803519062,
    "composite_score": 0.8458003892376377,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "DIAB_002",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 47.85402513721878,
    "chrf": 71.145658785242,
    "bertscore_precision": 0.9501451253890991,
    "bertscore_recall": 0.9540285468101501,
    "bertscore_f1": 0.9520829319953918,
    "labse_similarity": 0.8814640641212463,
    "comet_score": 0.8805490136146545,
    "flesch_reading_ease": 44.252139997444544,
    "flesch_kincaid_grade": 11.240006388687764,
    "composite_score": 0.8366274591416123,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 66.67141034758473,
    "chrf": 86.27306522121104,
    "bertscore_precision": 0.9716644883155823,
    "bertscore_recall": 0.9765909314155579,
    "bertscore_f1": 0.9741214513778687,
    "labse_similarity": 0.9171674251556396,
    "comet_score": 0.9118771553039551,
    "flesch_reading_ease": 56.94495753715498,
    "flesch_kincaid_grade": 9.031237488626026,
    "composite_score": 0.8997202174498786,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 26.36059151114553,
    "chrf": 64.87137535961853,
    "bertscore_precision": 0.9418762922286987,
    "bertscore_recall": 0.939749002456665,
    "bertscore_f1": 0.9408114552497864,
    "labse_similarity": 0.8752819895744324,
    "comet_score": 0.8893918991088867,
    "flesch_reading_ease": 41.78157276995307,
    "flesch_kincaid_grade": 10.791327967806843,
    "composite_score": 0.8033154638176174,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_001",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 56.13745515977215,
    "chrf": 77.22901148697837,
    "bertscore_precision": 0.9666184186935425,
    "bertscore_recall": 0.9668266177177429,
    "bertscore_f1": 0.9667225480079651,
    "labse_similarity": 0.932397186756134,
    "comet_score": 0.8945801258087158,
    "flesch_reading_ease": 55.28333333333336,
    "flesch_kincaid_grade": 9.511428571428574,
    "composite_score": 0.8721222055960349,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 67.66832191747582,
    "chrf": 80.83848773320722,
    "bertscore_precision": 0.978753924369812,
    "bertscore_recall": 0.9773879051208496,
    "bertscore_f1": 0.9780704379081726,
    "labse_similarity": 0.9121752977371216,
    "comet_score": 0.9134622812271118,
    "flesch_reading_ease": 79.65745873359494,
    "flesch_kincaid_grade": 4.691828575294277,
    "composite_score": 0.8931478147439407,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 49.00964391597977,
    "chrf": 70.31509664554392,
    "bertscore_precision": 0.9679262638092041,
    "bertscore_recall": 0.9628553986549377,
    "bertscore_f1": 0.9653841853141785,
    "labse_similarity": 0.9207236766815186,
    "comet_score": 0.9048143625259399,
    "flesch_reading_ease": 75.08836763229601,
    "flesch_kincaid_grade": 5.185298293417471,
    "composite_score": 0.8544458704463378,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 17.411702004368337,
    "chrf": 52.67430410338365,
    "bertscore_precision": 0.8912261724472046,
    "bertscore_recall": 0.8986707329750061,
    "bertscore_f1": 0.8949329257011414,
    "labse_similarity": 0.8920812606811523,
    "comet_score": 0.6787930727005005,
    "flesch_reading_ease": 83.7604841974664,
    "flesch_kincaid_grade": 4.21106503852684,
    "composite_score": 0.7130175561811417,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 55.48685332099341,
    "chrf": 76.33236715637224,
    "bertscore_precision": 0.9501031637191772,
    "bertscore_recall": 0.9502769708633423,
    "bertscore_f1": 0.9501900672912598,
    "labse_similarity": 0.9116971492767334,
    "comet_score": 0.8931033611297607,
    "flesch_reading_ease": 82.48269034236075,
    "flesch_kincaid_grade": 4.44812979049566,
    "composite_score": 0.8606576943807166,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 23.504799151242153,
    "chrf": 54.96582885416548,
    "bertscore_precision": 0.9020711779594421,
    "bertscore_recall": 0.9262473583221436,
    "bertscore_f1": 0.9139994382858276,
    "labse_similarity": 0.8823878765106201,
    "comet_score": 0.7151957154273987,
    "flesch_reading_ease": 76.9575626231354,
    "flesch_kincaid_grade": 4.970346186321418,
    "composite_score": 0.7354298780772123,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 49.66648462109025,
    "chrf": 71.42914449867007,
    "bertscore_precision": 0.9329723119735718,
    "bertscore_recall": 0.9324432611465454,
    "bertscore_f1": 0.9327077269554138,
    "labse_similarity": 0.8905805349349976,
    "comet_score": 0.861646294593811,
    "flesch_reading_ease": 70.81257607348137,
    "flesch_kincaid_grade": 6.435442916713626,
    "composite_score": 0.8301502000911719,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 23.14874636321511,
    "chrf": 61.39918047885452,
    "bertscore_precision": 0.9538977742195129,
    "bertscore_recall": 0.949153482913971,
    "bertscore_f1": 0.9515197277069092,
    "labse_similarity": 0.9223353266716003,
    "comet_score": 0.8730185031890869,
    "flesch_reading_ease": 72.65060260946485,
    "flesch_kincaid_grade": 5.459941766180158,
    "composite_score": 0.8034251265251614,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "RESP_002",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 61.57963812363534,
    "chrf": 79.61908923460766,
    "bertscore_precision": 0.9419167041778564,
    "bertscore_recall": 0.9430309534072876,
    "bertscore_f1": 0.9424735307693481,
    "labse_similarity": 0.9192695021629333,
    "comet_score": 0.8833531141281128,
    "flesch_reading_ease": 81.45599131323455,
    "flesch_kincaid_grade": 4.591333673990803,
    "composite_score": 0.8684425101709661,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 56.24082535841589,
    "chrf": 79.38557820822065,
    "bertscore_precision": 0.961570143699646,
    "bertscore_recall": 0.9643335342407227,
    "bertscore_f1": 0.9629498720169067,
    "labse_similarity": 0.9074835181236267,
    "comet_score": 0.908015251159668,
    "flesch_reading_ease": 58.744247860292234,
    "flesch_kincaid_grade": 8.1739215008213,
    "composite_score": 0.8727046706904612,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 42.34070813854807,
    "chrf": 70.49303027162213,
    "bertscore_precision": 0.9474450349807739,
    "bertscore_recall": 0.9481391906738281,
    "bertscore_f1": 0.9477919936180115,
    "labse_similarity": 0.908173143863678,
    "comet_score": 0.8933423757553101,
    "flesch_reading_ease": 49.86849462365592,
    "flesch_kincaid_grade": 9.237488479262673,
    "composite_score": 0.8373880743429479,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 43.71776519911429,
    "chrf": 69.45558698249839,
    "bertscore_precision": 0.9467329382896423,
    "bertscore_recall": 0.9494321942329407,
    "bertscore_f1": 0.9480806589126587,
    "labse_similarity": 0.9071081876754761,
    "comet_score": 0.8714489936828613,
    "flesch_reading_ease": 55.19162302130155,
    "flesch_kincaid_grade": 8.311242915770965,
    "composite_score": 0.8316092293024699,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 47.51448086137489,
    "chrf": 76.30582272375418,
    "bertscore_precision": 0.9370546340942383,
    "bertscore_recall": 0.9375780820846558,
    "bertscore_f1": 0.9373162984848022,
    "labse_similarity": 0.8952183127403259,
    "comet_score": 0.8702939748764038,
    "flesch_reading_ease": 62.506079266295444,
    "flesch_kincaid_grade": 7.822543399934496,
    "composite_score": 0.8397852607596129,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 28.126712647903723,
    "chrf": 59.06433022658932,
    "bertscore_precision": 0.9266887903213501,
    "bertscore_recall": 0.9326547384262085,
    "bertscore_f1": 0.9296622276306152,
    "labse_similarity": 0.8132842779159546,
    "comet_score": 0.8356022834777832,
    "flesch_reading_ease": 61.558583250107006,
    "flesch_kincaid_grade": 7.498286013221097,
    "composite_score": 0.767179302729609,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 50.595251482714815,
    "chrf": 74.03527208218647,
    "bertscore_precision": 0.9564497470855713,
    "bertscore_recall": 0.9574897289276123,
    "bertscore_f1": 0.9569694399833679,
    "labse_similarity": 0.9370614290237427,
    "comet_score": 0.9049371480941772,
    "flesch_reading_ease": 57.602625147812404,
    "flesch_kincaid_grade": 8.292713178294573,
    "composite_score": 0.8623855644292977,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 37.8243716947464,
    "chrf": 68.38585764802396,
    "bertscore_precision": 0.9396750926971436,
    "bertscore_recall": 0.9425132870674133,
    "bertscore_f1": 0.9410920739173889,
    "labse_similarity": 0.9030400514602661,
    "comet_score": 0.8874446749687195,
    "flesch_reading_ease": 55.067159740754875,
    "flesch_kincaid_grade": 8.397931757529552,
    "composite_score": 0.825199959376232,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "MED_001",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 33.04789776233991,
    "chrf": 67.91183933881129,
    "bertscore_precision": 0.9122774004936218,
    "bertscore_recall": 0.9262160062789917,
    "bertscore_f1": 0.9191939234733582,
    "labse_similarity": 0.9439612030982971,
    "comet_score": 0.7733573913574219,
    "flesch_reading_ease": 65.8697569990563,
    "flesch_kincaid_grade": 7.3352579427492905,
    "composite_score": 0.792805422271579,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 59.892423959669465,
    "chrf": 81.33470948369894,
    "bertscore_precision": 0.927792489528656,
    "bertscore_recall": 0.9358211755752563,
    "bertscore_f1": 0.9317895770072937,
    "labse_similarity": 0.906338095664978,
    "comet_score": 0.884618878364563,
    "flesch_reading_ease": 57.9022763595689,
    "flesch_kincaid_grade": 8.987361436303832,
    "composite_score": 0.8638537000115423,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 44.743340020361586,
    "chrf": 72.29381260285803,
    "bertscore_precision": 0.9330289959907532,
    "bertscore_recall": 0.9360696077346802,
    "bertscore_f1": 0.9345467686653137,
    "labse_similarity": 0.8863245248794556,
    "comet_score": 0.8830581903457642,
    "flesch_reading_ease": 55.24666666666667,
    "flesch_kincaid_grade": 9.007857142857144,
    "composite_score": 0.8315775420865748,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 53.660650678003016,
    "chrf": 76.71062947263306,
    "bertscore_precision": 0.9502223134040833,
    "bertscore_recall": 0.9545232057571411,
    "bertscore_f1": 0.9523678421974182,
    "labse_similarity": 0.8423728346824646,
    "comet_score": 0.9001357555389404,
    "flesch_reading_ease": 62.05612244897961,
    "flesch_kincaid_grade": 8.081734693877554,
    "composite_score": 0.847945453367406,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 64.4260599707388,
    "chrf": 84.31992597183081,
    "bertscore_precision": 0.9576263427734375,
    "bertscore_recall": 0.9605536460876465,
    "bertscore_f1": 0.9590877890586853,
    "labse_similarity": 0.8823416829109192,
    "comet_score": 0.8967970609664917,
    "flesch_reading_ease": 64.33954782811637,
    "flesch_kincaid_grade": 7.993711990820426,
    "composite_score": 0.8792998874698973,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 43.45312434639627,
    "chrf": 71.82790560052055,
    "bertscore_precision": 0.9473288059234619,
    "bertscore_recall": 0.9494965672492981,
    "bertscore_f1": 0.9484115242958069,
    "labse_similarity": 0.8948465585708618,
    "comet_score": 0.8568840026855469,
    "flesch_reading_ease": 57.58327956989251,
    "flesch_kincaid_grade": 8.89488479262673,
    "composite_score": 0.8289087524214782,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 52.96321467934091,
    "chrf": 78.92531014235087,
    "bertscore_precision": 0.9423022270202637,
    "bertscore_recall": 0.9420949220657349,
    "bertscore_f1": 0.9421985745429993,
    "labse_similarity": 0.9022607803344727,
    "comet_score": 0.8817400932312012,
    "flesch_reading_ease": 60.845337711679406,
    "flesch_kincaid_grade": 8.654684303908002,
    "composite_score": 0.8548979316304618,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 39.95797760712192,
    "chrf": 71.97089483645738,
    "bertscore_precision": 0.9186878800392151,
    "bertscore_recall": 0.9385556578636169,
    "bertscore_f1": 0.9285154938697815,
    "labse_similarity": 0.8737772107124329,
    "comet_score": 0.8951374292373657,
    "flesch_reading_ease": 55.06374697793899,
    "flesch_kincaid_grade": 8.84113489185339,
    "composite_score": 0.8250087674745705,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "EMER_001",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 41.813716312109015,
    "chrf": 73.70620505263835,
    "bertscore_precision": 0.9363642930984497,
    "bertscore_recall": 0.9367403984069824,
    "bertscore_f1": 0.9365523457527161,
    "labse_similarity": 0.8790279626846313,
    "comet_score": 0.855738639831543,
    "flesch_reading_ease": 67.80271574987736,
    "flesch_kincaid_grade": 7.771069981282597,
    "composite_score": 0.8230789801116933,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 54.40799944106544,
    "chrf": 75.78301674625936,
    "bertscore_precision": 0.9486508369445801,
    "bertscore_recall": 0.9490978717803955,
    "bertscore_f1": 0.948874294757843,
    "labse_similarity": 0.8991379141807556,
    "comet_score": 0.8904759883880615,
    "flesch_reading_ease": 76.83483899821111,
    "flesch_kincaid_grade": 5.829302325581395,
    "composite_score": 0.8551913929209738,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 32.62616123485396,
    "chrf": 62.99046277632756,
    "bertscore_precision": 0.9441443681716919,
    "bertscore_recall": 0.9479172229766846,
    "bertscore_f1": 0.9460270404815674,
    "labse_similarity": 0.8420827984809875,
    "comet_score": 0.882655680179596,
    "flesch_reading_ease": 68.60601776130848,
    "flesch_kincaid_grade": 6.566196013289037,
    "composite_score": 0.800000447284912,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 50.071576737215594,
    "chrf": 71.40636680912273,
    "bertscore_precision": 0.9448463320732117,
    "bertscore_recall": 0.9456814527511597,
    "bertscore_f1": 0.9452637434005737,
    "labse_similarity": 0.8471705913543701,
    "comet_score": 0.8889646530151367,
    "flesch_reading_ease": 77.22277987421387,
    "flesch_kincaid_grade": 5.652240391334729,
    "composite_score": 0.83243553149573,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 53.23373348553355,
    "chrf": 76.25438753487816,
    "bertscore_precision": 0.9508514404296875,
    "bertscore_recall": 0.9522386193275452,
    "bertscore_f1": 0.9515445828437805,
    "labse_similarity": 0.845477283000946,
    "comet_score": 0.8931453824043274,
    "flesch_reading_ease": 79.08133376073859,
    "flesch_kincaid_grade": 5.431530709065264,
    "composite_score": 0.8454604918422559,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 30.25883855849166,
    "chrf": 62.27167515720178,
    "bertscore_precision": 0.9276015162467957,
    "bertscore_recall": 0.9358811378479004,
    "bertscore_f1": 0.9317229390144348,
    "labse_similarity": 0.8752357959747314,
    "comet_score": 0.8666408061981201,
    "flesch_reading_ease": 67.63221458266712,
    "flesch_kincaid_grade": 6.5915094339622655,
    "composite_score": 0.794890593743101,
    "suitability_rating": "caution",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 49.73757197933676,
    "chrf": 75.56046955900516,
    "bertscore_precision": 0.9453732967376709,
    "bertscore_recall": 0.9469968676567078,
    "bertscore_f1": 0.9461843967437744,
    "labse_similarity": 0.8408278226852417,
    "comet_score": 0.8933898210525513,
    "flesch_reading_ease": 73.79286566390041,
    "flesch_kincaid_grade": 6.174085901995657,
    "composite_score": 0.8384466151411629,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 36.141931545981556,
    "chrf": 66.61758377072553,
    "bertscore_precision": 0.9357337951660156,
    "bertscore_recall": 0.9373363852500916,
    "bertscore_f1": 0.9365343451499939,
    "labse_similarity": 0.8562864661216736,
    "comet_score": 0.8883137702941895,
    "flesch_reading_ease": 68.33098290598294,
    "flesch_kincaid_grade": 6.824320987654321,
    "composite_score": 0.81036434654495,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_001",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 46.79305569370156,
    "chrf": 74.28473894173445,
    "bertscore_precision": 0.9294847249984741,
    "bertscore_recall": 0.9360122084617615,
    "bertscore_f1": 0.9327371120452881,
    "labse_similarity": 0.9090325832366943,
    "comet_score": 0.8162804841995239,
    "flesch_reading_ease": 82.68783935242843,
    "flesch_kincaid_grade": 5.023349937733499,
    "composite_score": 0.8239179354171096,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "spanish",
    "bleu": 69.56739851391588,
    "chrf": 84.6907529268978,
    "bertscore_precision": 0.9813337326049805,
    "bertscore_recall": 0.9815826416015625,
    "bertscore_f1": 0.9814581871032715,
    "labse_similarity": 0.8924833536148071,
    "comet_score": 0.9159641265869141,
    "flesch_reading_ease": 73.28285195936141,
    "flesch_kincaid_grade": 6.799749118805725,
    "composite_score": 0.898528686404934,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "chinese_simplified",
    "bleu": 52.82767425893026,
    "chrf": 76.48504439927048,
    "bertscore_precision": 0.9657474756240845,
    "bertscore_recall": 0.9683808088302612,
    "bertscore_f1": 0.9670623540878296,
    "labse_similarity": 0.864513635635376,
    "comet_score": 0.9101972579956055,
    "flesch_reading_ease": 71.43907193863184,
    "flesch_kincaid_grade": 6.7623167155425215,
    "composite_score": 0.8581259887101613,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "vietnamese",
    "bleu": 56.15133067695442,
    "chrf": 77.2340155418705,
    "bertscore_precision": 0.9737530946731567,
    "bertscore_recall": 0.974937915802002,
    "bertscore_f1": 0.9743451476097107,
    "labse_similarity": 0.8612728714942932,
    "comet_score": 0.9097329378128052,
    "flesch_reading_ease": 70.8842600817197,
    "flesch_kincaid_grade": 6.918636313647863,
    "composite_score": 0.8639937070247332,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "tagalog",
    "bleu": 61.036870151922734,
    "chrf": 81.16775971452479,
    "bertscore_precision": 0.9653705358505249,
    "bertscore_recall": 0.9687742590904236,
    "bertscore_f1": 0.9670694470405579,
    "labse_similarity": 0.8519996404647827,
    "comet_score": 0.8904879093170166,
    "flesch_reading_ease": 75.92869565217393,
    "flesch_kincaid_grade": 6.3952173913043495,
    "composite_score": 0.8659312492580878,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "russian",
    "bleu": 45.99318749619595,
    "chrf": 71.6150424294036,
    "bertscore_precision": 0.9505316019058228,
    "bertscore_recall": 0.9529083967208862,
    "bertscore_f1": 0.9517185091972351,
    "labse_similarity": 0.8308223485946655,
    "comet_score": 0.8945403099060059,
    "flesch_reading_ease": 71.4506901925773,
    "flesch_kincaid_grade": 6.961041279984965,
    "composite_score": 0.8287308510949065,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "arabic",
    "bleu": 62.00320427534156,
    "chrf": 81.1855897495302,
    "bertscore_precision": 0.9621258974075317,
    "bertscore_recall": 0.9636056423187256,
    "bertscore_f1": 0.9628652334213257,
    "labse_similarity": 0.8764722347259521,
    "comet_score": 0.90297931432724,
    "flesch_reading_ease": 73.21692597531478,
    "flesch_kincaid_grade": 6.832861440178629,
    "composite_score": 0.8736804344530349,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "korean",
    "bleu": 38.19609604366452,
    "chrf": 68.71844658950248,
    "bertscore_precision": 0.9461817145347595,
    "bertscore_recall": 0.9493641257286072,
    "bertscore_f1": 0.9477702379226685,
    "labse_similarity": 0.8564311265945435,
    "comet_score": 0.8976008296012878,
    "flesch_reading_ease": 67.70718767685342,
    "flesch_kincaid_grade": 7.063795628183367,
    "composite_score": 0.8212912700239494,
    "suitability_rating": "suitable",
    "errors": []
  },
  {
    "doc_id": "SURG_002",
    "model": "kimi-k2",
    "target_language": "haitian_creole",
    "bleu": 53.50318106872098,
    "chrf": 76.49303442595703,
    "bertscore_precision": 0.9545069932937622,
    "bertscore_recall": 0.9528430104255676,
    "bertscore_f1": 0.9536741971969604,
    "labse_similarity": 0.863761305809021,
    "comet_score": 0.8854502439498901,
    "flesch_reading_ease": 76.93413036248754,
    "flesch_kincaid_grade": 6.415255514909656,
    "composite_score": 0.8484598140160213,
    "suitability_rating": "suitable",
    "errors": []
  }
]